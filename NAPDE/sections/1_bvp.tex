\section{Boundary Value Problems}
\subsection{Weak Formulation}
Let's consider a problem 
\begin{equation}
    \begin{cases}
        \mathcal{L}u = f & \text{in }\Omega \\
        + \text{B.C.} & \text{on }\partial\Omega
    \end{cases}
\end{equation}
\begin{itemize}
    \item \(\Omega\): open bounded domain in \(\real^d\), with \(d = 2,3\)
    \item \(\partial\Omega\): boundary of \(\Omega\)
    \item \(f\): given 
    \item B.C. accordingly to \(\mathcal{L}\)
    \item \(\mathcal{L}\): \(2^{\text{nd}}\) order operator, like:
    \begin{enumerate}
        \item \(\mathcal{L}u = -\div(\mu\grad u) +\vect{b}\cdot\grad u + \sigma u\) {\hspace*{\fill} (non-conservative form)}
        \item \(\mathcal{L}u = -\div(\mu \grad u) + \div(\vect{b}u) + \sigma u\) {\hspace*{\fill} (conservative form)}
    \end{enumerate}
    \begin{itemize}
        \item \(\mu \in L^\infty(\Omega), \quad \mu(\vect{x})\geq \mu_0 > 0\) {\hspace*{\fill} uniformly bounded from below}
        \item \(\vect{b} \in (L^\infty(\Omega))^d\) {\hspace*{\fill} transport term}
        \item \(\sigma \in L^2(\Omega)\) {\hspace*{\fill} reaction term}
        \item \(f \in L^2(\Omega)\) {\hspace*{\fill} can be less regular}
    \end{itemize}
\end{itemize}


\subsection*{General elliptic problems}
Consider 
\begin{equation}
    \begin{cases}
        -\div(\mu \grad u)+ \vect{b}\cdot \grad u + \sigma u = f& \text{in } \Omega \quad g \in L^2(\Gamma_N) \\
        u = 0 & \txt{on }\Gamma_D \quad \partial\Omega = \Gamma_D \cup \Gamma_N \\

        \mu \grad u \cdot \vect{n} = g & \txt{on } \Gamma_N \quad \interior{\Gamma_D} \cap \interior{\Gamma_N} = \emptyset
    \end{cases}
\end{equation}
Suppose that \(f \in L^2(\Omega)\) and \(\mu, \sigma \in L^\infty(\Omega)\). Also suppose that \(\exists \; \mu_0 > 0 \txt{ s.t. } \mu(\vect{x}) \geq \mu_0\), and \(\sigma(\vect{x}) \geq 0\) a.e. on \(\Omega\).  
Then, given a test function \(v\), we multiply the equation by \(v\), and integrate on the domain \(\Omega\)
\begin{equation*}
    \int_\Omega \left[-\div(\mu \grad u)+ \vect{b}\cdot \grad u + \sigma u\right] v \,  = \int_\Omega f v 
\end{equation*}
By applying Green's formula 
\begin{equation*}
    \underbrace{\int_\Omega \mu\grad u \cdot \grad v  + \int_\Omega \vect{b} \cdot \grad u v + \int_\Omega \sigma u v}_{=: a(u,v)} = \int_\Omega f v +\underbrace{\int_{\Gamma_D} \mu \grad u \cdot \vect{n} v}_{= 0 \txt{ if } v\vert_{\Gamma_D} = 0} + \int_{\Gamma_N} \underbrace{\mu \grad u \cdot \vect{n}}_{= g} v 
\end{equation*}
So the weak formulation of the problem is 
\begin{equation}
    \begin{cases}
        \txt{Find } u \in V & V = \left\{v \in H^1(\Omega), v\vert_{\Gamma_D} = 0\right\} =: H^1_{\Gamma_D}(\Omega)\\
        a(u,v) = \scalarproduct{F}{v} & \forall \; v \in V \label{Weak Formulation of Boundary Value Problems}
    \end{cases}
\end{equation}
where \(a: V \times V \to \real\) is a bilinear form and \(F:V \to \real\) is a linear form s.t. \(\scalarproduct{F}{v} \equiv F(v) = \int_\Omega fv + \int_{\Gamma_N} gv\).
\begin{background}\begin{theorem}[Lax-Milgram]
    Assume that 
    \begin{itemize}
        \item \(V\) Hilbert space with \(\normdot\) and inner product \((\cdot, \cdot)\)
        \item \(F \in V^*: \abs*{F(v)} \leq \norm*{F}_{V^*}\norm*{v} \; \forall \; v \in V\)
        \item \(a\) continuous: \(\exists \; M > 0: \abs{a(u,v)} \leq M \norm*{u}\norm*{v} \; \forall \; u,v \in V\)
        \item \(a\) coercive: \(\exists \; \alpha > 0: a(v,v) \geq \alpha\norm*{v}^2 \; \forall \; v \in V\)
    \end{itemize}
    Then, there exists a unique solution \(u\) of \ref*{Weak Formulation of Boundary Value Problems}
\end{theorem}\end{background}
Moreover 
\[
    \alpha \norm*{u}^2 \leq a(u,u) = F(u) \leq \norm*{F}_{V^*} \norm*{u}
\]
where \(\alpha\) is the coercivity costant. Hence
\[
    \norm*{u} \leq \frac{\norm*{F}_{V^*}}{\alpha} \to \txt{stability/continuous dependence on data}
\]
But what if some of the assumptions of Lax-Milgram (in particular coercivity) are not satisfied?

We need a slightly more general problem to formulate Nečas theorem:
\begin{equation}
    \begin{cases}
        \txt{find } u \in V \\
        a(u,w) = \scalarproduct{F}{w} & \forall w \in W \label{Generalized weak formulation}
    \end{cases}
\end{equation}
They belong to different spaces: W for the test function, V the solutions
\begin{background}\begin{theorem}[Nečas]
    Assume that \(F \in W^*\). Consider the following conditions:
    \begin{itemize}
        \item \(a\) continuous: \(\exists \; M > 0: \abs*{a(u,w)} \leq M \norm*{u}_V \norm*{w}_W \; \forall \; u \in V, w \in W\)
        \item \(\inf-\sup\) condition: \(\exists \; \alpha > 0: \forall \; v \in V \quad \sup_{w \in W \setminus \left\{0\right\}} \frac{a(v,m)}{\norm*{w}_W} \geq \alpha \norm*{v}_V\)
        \item \(\forall \; w \in W, w \neq 0, \exists \; v \in V : a(v,w) \neq 0\)
    \end{itemize}
    These conditions are necessary and sufficient for the existence and uniqueness of a solution of \ref*{Generalized weak formulation}, for any \(F \in W^*\). Moreover 
    \[
        \norm*{u}_V \leq \frac{1}{\alpha}\norm*{F}_{W^*}
    \]
\label{Nečas}
\end{theorem}
\end{background}
When \(W=V\) Lax-Milgram provides necessary and sufficient conditions for existence and uniqueness of solutions.

Going back to 
\begin{equation*}
    \begin{cases}
        \mathcal{L}u = f & \text{in }\Omega \\
        + \text{B.C.} & \text{on }\partial\Omega
    \end{cases}
\end{equation*}
What could be our choice of \(V\)? Given that
\[
    u\in V : a(u,v) = F(v) \quad \forall \; v \in V
\]
and 
\[
    a(u,v) = \int_\Omega \mu \underbrace{\grad u \grad v}_{\grad u, \grad v \in L^2} + \int_\Omega b \underbrace{\grad u v}_{\in L^1} + \int_\Omega \sigma \underbrace{u v}_{\in L^1}
\]
We want to choose \(v\) in order to have all of these integrable \[\Rightarrow V = \left\{v \in L^2(\Omega), \grad u \in \left[L^2(\Omega)\right]^d, v\vert_{\Gamma_D} = 0\right\} = V_{\Gamma_D}\].

Knowing that a Sobolev space 
\[
    H^1 = \left\{v \in L^2(\Omega), \grad u \in \left[L^2(\Omega)\right]^d\right\}
\]
we can say \(V_{\Gamma_D} = \left\{v \in H^1(\Omega): v\limited{\Gamma_D}= 0\right\}\), and if \(\Gamma_D = \partial\Omega\), then \(V_{\Gamma_D} = H^1_0\)
\subsection{Approximation}
Recall for a moment the weak formulation of a generic elliptic problem 
\begin{equation}
    \begin{cases}
        \txt{Find } u \in V \\
        a(u,v) = \scalarproduct{F}{v} & \forall \; v \in V \label{Weak Formulation of Boundary Value Problems - 2}
    \end{cases}
\end{equation}
with \(V\) being an appropriate Hilbert space, subset of \(H^1(), a(\cdot,\cdot)\) being a continuous and coercive bilinear forrm from \(V \times V \to \real\), \(F(\cdot)\) being a continuous linear functional from \(V \to \real\).

Let \(V_h \subset V\) be a family of spaces that depends on a parameter \(h > 0\), such that \(\dim V_h = N_h < \infty\).
We can rewrite the weak formulation 
\begin{equation}
    \begin{cases}
        \txt{Find } u_h \in V_h\\
        a(u_h,v_h) = \scalarproduct{F}{v_h} & \forall \; v_h \in V_h \label{Galerkin Problem Formula}
    \end{cases}
\end{equation}
and is called a \textbf{Galerkin problem}. Denoting with \(\left\{\phi_j, j = 1,2,\ldots,N_h\right\}\) a basis of \(V_h\), it is sufficient that the \eqref{Galerkin Problem Formula} is verified for each function of the basis. 
Also we need that 
\[
    a(u_h, \phi_i) = F(\phi_i) \quad i = 1, 2, \ldots , N_h
\]
Since \(u_h \in V_h\)
\[
    u_h(\vect{x})=\sum_{j=1}^{N_h} u_j \phi_j(\vect{x})
\]
where \(u_j\) are unknown coefficients. Then
\[
    \sum_{j=1}^{N_h}u_j a(\phi_j, \phi_i) = F(\phi_i)
\]
We denote by \(A\) the matrix made by \(a_{ij} = a(\phi_j, \phi_i)\) and \(\vect{f}\) the vector of \(F(\phi_i) = f_i\) components. If we denote the vector \(\vect{u}\) made by the unknown coefficients \(u_h\).
\begin{equation}
    A\vect{u} = \vect{f}
    \label{Linear system Galerkin}
\end{equation}
\begin{background}
    \begin{theorem}
    The stiffness matrix \(A\) associated to the Galerkin discretization of an elliptic problem, whose bilinear form is coercive is positive definite.
\end{theorem}
\begin{proof}
    Recall that a matrix \(B \in \real^{n\times n}\) is said to be positive definite if 
    \[
        \vect{v}^TB\vect{v} \geq 0 \quad \forall \; \vect{v} \in \real^n
    \]
    and
    \[
        \vect{v}^T B \vect{v} = 0 \Leftrightarrow \vect{v} = \vect{0}
    \]
    The correspondence 
    \[
        \vect{v} = (v_i) \in \real^{N_h} \longrightarrow v_h(x) = \sum_{j=1}^{N_h} v_j\phi_j \in V_h
    \]
    defines a bijection between \(V_h\) and \(\real^{N_h}\). Given a generic vector \(\vect{v} = (v_i)\) of \(\real^{N_h}\), thanks to the bilinearity and coercivity of \(a\) we obtain 
    
        \begin{align*}
        \vect{v}^T A \vect{v} & = \sum_{j=1}^{N_h}\sum_{i=1}^{N_h} v_i ai_j v_j \\
        & = \sum_{j=1}^{N_h}\sum_{i=1}^{N_h} v_ia(\phi_j, \phi_i)v_j\\
        & = \sum_{j=1}^{N_h}\sum_{i=1}^{N_h} a(v_j\phi_j, v_i \phi_i)\\
        & = a\left(\sum_{j=1}^{N_h}v_j\phi_j\sum_{i=1}^{N_h}v_i\phi_i\right)\\
        & = a(v_h,v_h) \geq \alpha \norm*{v_h}_V^2 \geq 0
        \end{align*}

    Moreover, if \(\vect{v}^T A \vect{v} = 0\), then \(\norm{v_h}_V^2 = 0\).
\end{proof}
\end{background}

\subsubsection*{Existence and uniqueness}
\begin{background}
    \begin{corollary}
    The solution of the Galerkin problem \eqref{Galerkin Problem Formula} exists and is unique.
\end{corollary}
\end{background}
To prove this we can prove that the solution to \eqref{Linear system Galerkin} exists and is unique. The matrix \(A\) is invertible as the unique solution of \(A\vect{u} = \vect{0}\) is the null solution, meaning that \(A\) is definite positive.
\subsection*{Stability}
\begin{corollary}
    The Galerkin method is stable, uniformly with respect to \(h\), by virtue of the following upper bound for the solution
    \[
        \norm{u_h}_V \leq \frac{1}{\alpha}\norm{F}_{V^*}
    \]
\end{corollary}
The stability of the method guarantees that the norm \(\norm{u_h}_V\) of the discrete solution remains bounded for \(h \to 0\). Equivalently it guarantees that \(\norm{u_h-w_h}_V \leq \frac{1}{\alpha}\norm{F-G}_{V^*}\) with \(u_h\) and \(w_h\) being numerical solution corresponding to different data \(F\) and \(G\).
\subsection*{Convergence}
\begin{background}
    \begin{lemma}[Galerkin orthogonality]
    The solution \(u_h\) of the Galerkin method satisfies 
    \begin{equation}
        a(u-u_h, v_h) = 0 \quad \forall \; v_h \in V_h \label{Galerkin orthogonality}
    \end{equation}
\end{lemma}

\begin{proof}
    Since \(V_h \subset V\), the exact solution \(u\) satisfies the weak problem \eqref{Weak Formulation of Boundary Value Problems - 2} for each element \(v = v_h \in V_h\), hence we have 
    \begin{equation}
        a(u, v_h) = F(v_h) \forall \; v_h \in V_h \label{Application of exact solution}
    \end{equation}
    By subtracting side by side \eqref{Galerkin Problem Formula} from \eqref{Application of exact solution}, we obtain 
    \[
        a(u,v_h)-a(u_h, v_h) = 0 \forall \; v_h \in V_h
    \]
    from which the claim follows.
\end{proof}
\end{background}

Also this can be generalized in the cases in which \(a(\cdot, \cdot)\) is not symmetric. Consider the value taken by the bilinear form when both its arguments are \(u-u_h\). If \(v_h\) is an arbitrary element of \(V_h\) we obtain 
\[
    a(u-u_h, u-u_h) = a(u-u_h, u-v_h) + a(u-u_h, v_h-u_h)
\]
The last term is null by \eqref{Galerkin orthogonality}. Moreover 
\[
    \abs*{a(u-u_h, u-v_h)} \leq M \norm{u-u_h}_V\norm{u-v_h}_V
\]
having exploited the continuity of the bilinear form. Also by the coercivity 
\[
    a(u-u_h, u-u_h) \geq \alpha \norm{u-u_h}^2_V
\]
hence 
\[
    \norm{u-u_h}_V \leq \frac{M}{\alpha} \norm{u-v_h}_V \quad \forall\; v_h \in V_h
\]
Such inequality holds for all functions \(v_h \in V_h\) and therefore we find 
\begin{equation}
   \underbrace{ \norm{u-u_h}_V}_{\text{Galerkin error}} \leq \frac{M}{\alpha} \underbrace{\inf_{w_h \in V_h} \norm{u - w_h}_V}_{\text{Best Approximation Error}} \label{Ceà Lemma}
\end{equation}
In order for the method to converge, it is sufficient that, for \(h \to 0\) the space \(V_h\) tends to saturate the entire space \(V\). 
\begin{equation}
    \lim_{h \to 0} \inf_{v_h \in V_h} \norm{v-v_h}_V= 0 \quad \forall \; v \in V \label{Saturation Property}
\end{equation}
In that case the Galerkin method is convergent and it can be written that
\[
    \lim_{h\to 0} \norm{u-u_h}_V = 0 \Leftrightarrow \text{convergence}
\]
Thie space \(V_h\) must be chosen carefully to satisfy the saturation property \eqref{Saturation Property}.
\subsection{Finite Element Method}
\subsubsection*{Partitions}
\begin{itemize}
    \item[\textbf{1D}]
    Let us suppose that \(\Omega\) is an interval \((a,b)\). How to create an approximation of the space \(H^1(a,b)\) that depend on a parameter \(h\). Consider a partition \(\mathcal{T}_h\) in \(N+1\) subintervals \(K_j = x_{j-1}, x_j\), having width \(h_j = x_j - x_{j-1}\) with 
    \begin{equation}
        a = x_0 < x_1 < \ldots < x_{N-1} < x_N = b \label{Partition of an interval}
    \end{equation}
    and set \(h = \max_j h_j\). 
    \item[\textbf{2D}] Now we can extend the FEM for multi-dimensional problems. For simplicity we will consider \(\Omega \subset \real^2\) with polygonal shapes \(\mathcal{T}_h\). In this case the partition is called a triangulation. We can define the discretized domain 
    \[
        \Omega_h = \text{int}\left(\bigcup_{K \in \mathcal{T}_h} K\right)
    \]
    in a way that the internal part of the union of the triangles \(\mathcal{T}_h\). Having set \(\text{diam}(K) = \max_{x,y \in K} \abs{x-y} = h_k\). Also, given \(\rho_K\) the measure of the diameter of the circle inscribed in the triangle \(K\), must be satisfied the condition that, for a suitable \(\delta > 0\) 
    \begin{equation}
        \frac{h_k}{\rho_k} \leq \delta \quad \forall \; K \in \mathcal{T}_h \label{Regularity of K}
    \end{equation}
    The condition \eqref{Regularity of K} excludes very deformed triangles.

\end{itemize}
\begin{background}
\begin{definition}[Seminorms]
    A seminorm is defined as 
    \[
        \abs{f}_k = \abs{f}_H^k (\Omega) = \sqrt{\sum_{\abs{\alpha} = k} \int_\Omega \left(D^\alpha f\right)^2 \, d\Omega}
    \]
    In particular 

        \begin{align*}
            \text{1D:}\quad  \abs{u}_{H^1(a,b)} & = \left(\norm{u_x}^2_{L^2(a,b)}\right)^{\frac{1}{2}} = \norm{u_x}^2_{L^2(a,b)} \\
              \abs{u}_{H^2(a,b)} & = \norm{u_{xx}}^2_{L^2(a,b)} \\
            \text{2D:}\quad  \abs{u}_{H^1(a,b)} & = \left(\norm{u_x}^2_{L^2(a,b)} + \norm{u_y}^2_{L^2(a,b)}\right)^{\frac{1}{2}} \\
             \abs{u}_{H^1(a,b)} & = \left(\norm{u_{xx}}^2_{L^2(a,b)} + \norm{u_{xy}}^2_{L^2(a,b)} + \norm{u_{yx}}^2_{L^2(a,b)} +\norm{u_{yy}}^2_{L^2(a,b)}\right)^{\frac{1}{2}} \\
        \end{align*}
    Always true that \(\abs{u}_{H^q} \leq \norm{u}_{H^q}\)
\end{definition}
\end{background}
The problem is always: 
\begin{align}
    \begin{split} 
        \text{find } u_h \in \;&V_h : a(u_h, v_h) = F(v_h) \quad \forall \; v_h \in V_h \\
        &\downarrow\\
        &V_h = \left\lbrace v_h \in X^r_h : v_h\vert_{\Gamma_D} = 0\right\rbrace \; \; r \geq 1 \label{Galerkin weak formulation}
    \end{split}   
\end{align}

Since the functions of \(H^1(a,b)\) are continuous on \([a,b]\), it is possible to create the family of spaces 
\begin{equation}
    X_h^r = \left\{v_h \in \mathcal{C}^0\left(\overline{\Omega}\right) : v_h \vert_{K_j} \in \mathbb{P}_r \;\; \forall \; K_j \in \mathcal{T}_h\right\}, \quad r= 1,2,\ldots \label{Family of spaces FEM}
\end{equation}
having denoted by \(\mathbb{P}_r\) the space of polynomials with degree lower or equal to \(r\) in the variable \(x\). All these spaces are subspaces of \(H^1(a,b)\) as they are constituted by differentiable functions except for at most a finite number of points (the vertices of the partition). It is convenient to sekect a basis for the \(X^r_h\) space that is \textit{Lagrangian}.

    \begin{align*}
        \mathbb{P}^r:\quad &\text{1D} \quad &p(x) =& \sum_{k=0}^r a_k x^k &\text{intervals} \\
        \\
                      &\text{2D}  \quad &p(x_1, x_2) =& \sum_{\mathclap{\substack{k,m=0 \\ k + m \leq r}}}^r a_{km} x_1^k x_2^m  &\text{triangles} \\
         \\
                      &\text{3D} \quad &p(x_1, x_2, x_3) =& \sum_{\mathclap{\substack{k,m,n=0 \\ k + m + n  \leq r}}}^r a_{kmn} x_1^k x_2^m x_3^n &\text{tetrahedra}
    \end{align*}

\subsubsection*{The space \(X^1_h\)}
The space is constituted by the functions of the partition \eqref{Partition of an interval}. Since only a straight line can pass through different points, the degrees of freedom (DOF, the number of values we need to assign to the basis to define the functions)  of the functions will be equal to the number \(N+2\) of vertices of the partition. It follows naturally that \(\left\lbrace\phi_i\right\rbrace, i = 0, 1, \ldots, N, N+1\).
In this case the basis functions are characterized by the following properties 
\[
    \phi_i \in X^1_h \text{ s.t } \phi_i(x_j) = \delta_{ij}, \quad i, j = 0, 1, \ldots, N, N+1
\]
where \(\delta_{ij}\) is the Kronecker delta. So we have our basis function that have value \(1\) in the node \(x_j\) and \(0\) elsewhere.

The formula for the basis function is then given by 
\begin{equation}
    \phi_i(x) = \begin{cases}
        \frac{x-x_{i-1}}{x_i - x_{i-1}} & \text{for }x_{i-1} \leq x \leq x_i \\
        \frac{x-x_{i+1}}{x_{i+1} - x_i} & \text{for }x_i \leq x \leq x_{i+1} \\
        0 & \text{otherwise}
    \end{cases}
\end{equation}
\subsubsection*{The space \(X^2_h\)}
In this case polynomials are of degree 2, so the points necessary to evaluate them are \(3\). The chosen points for every element of the partition \(\mathcal{T}_h\). The nodes from the interval goes from \(a = x_0\) to \(b = x_{2N + 2}\), so that midpoints are the nodes with odd indices. As the previous case the basis is Lagrangian
\[
    \phi_i \in X^2_h \text{ s.t } \phi_i(x_j) = \delta_{ij}, \quad i, j = 0, 1, \ldots, 2N+2
\]
\subsubsection*{The space \(V_h\)}
This space is generated by 
\[
    V_h = \left\{v_h \in X^r_h : v_h(a) = v_h(b) = 0 \right\}
\]
Having defined a basis \(\left\lbrace\phi_j(\vect{x})\right\rbrace_{j=1}^{N_h}\) for the space \(V_h\), each \(v_h\) can be expanded as a linear combination of elements of the basis, suitably weighted by coefficients \(\left\{v_j\right\}_{j=1}^{N_h}\)
\[
    v_h(\vect{x}) = \sum_{j=1}^{N_h} v_j \phi_j(\vect{x})
\]
A basis is called Lagrangian if it satisfies the following properties
\[
    \phi_i(\vect{x}_j) = \delta_{ij} \quad \forall \; 1 \leq i,j \leq N_h
\]
and then the following property holds:
\[
    v_h(\vect{x}_j) = v_j \quad \forall \; 1 \leq i,j \leq N_h
\]
The solution of the Finite Element Method, \(u_h\) can be written as 
\begin{equation}
    u_h(\vect{x}) = \sum_{j=1}^{N_h} u_j\phi_j (\vect{x}) \label{Solution of Galerkin FEM}
\end{equation}
In \eqref{Galerkin weak formulation} take \(v_h = \phi_j\) \(\forall \; j = 1,\ldots, N_h \) such that \(a(u_h,\phi_i) = F(\phi_i)\) \(\forall \; i = 1,\ldots,N_h\). Then use \eqref{Solution of Galerkin FEM} to obtain 
\begin{align*}
    &a\left( \sum_{j=1}^{N_h} u_j\phi_j (\vect{x}), \phi_i \right) = \underbrace{F(\phi_i)}_{F_i} \\ 
    &\Rightarrow \sum_{j=1}^{N_h} \underbrace{a(\phi_j, \phi_i)}_{\mathclap{\substack{a_{ij} \text{ elements}\\ \text{of } A}}} u_j (\vect{x}) = F_i \quad i = 1, \ldots, N_h \\
    &\Rightarrow A\,\vect{u} = \vect{F}
\end{align*}
Which is a linear system of dimension \(N_h \times N_h\) with \(\vect{F}\) the right hand side (RHS), \(A\) the stiffness matrix and \(\vect{u}\) a vector of unknown nodal values of the solution \(u_h\).
\subsection{Advection Diffusion Reaction Problem}
\begin{equation*}
   \begin{cases}
       Lu = \underbrace{-\div (\mu\grad u)}_{\txt{diffusion}} + \underbrace{\vect{b} \cdot \grad u}_{\txt{advection}} + \underbrace{\sigma u}_{\txt{reaction}} = f & \txt{in }\Omega \\
       \txt{BC }& \txt{on }\partial\Omega\\
   \end{cases}
\end{equation*}
Lax-Milgram tells us that if \(\sigma - \frac{1}{2}\div\vect{b} \geq \gamma > 0\) then \(\exists!\) a solution to the problem. But what if these conditions are not satisfied? We can use Nečas theorem (\eqref{Nečas}) with equivalent assumptions:
\begin{itemize}
    \item Weak coercivity (Gårding inequality): 
    \[
        \exists \; \alpha, \lambda : a(v,v) \geq \alpha \norm{v}^2-\norm{v}_{L^2(\Omega)}^2 \quad \forall \; v \in V
    \]
    \item Uniqueness condition (typically proven by maximum principle):
    \[
        (a(u,v) = 0 \; \forall \; v \in V) \Rightarrow u = 0
    \]
\end{itemize}
If \(A\) is spd (symmetric positive defined) then \(K_2(A) = \frac{\lambda_{max}(A)}{\lambda_{min}(A)}\)
\begin{background}
    \begin{proposition}
        If \(a(\cdot,\cdot)\) is symmetric and coercive, then \(A\) is spd.
    \end{proposition}

    \begin{proof}
        Symmetry: \(A_{ij} = a(\phi_j,\phi_i) = a(\phi_i,\phi_j) = A_{ji}\)

        \(\forall \; \vect{v} \in \real^{N_h}\):
        \begin{align*}
            \vect{v}^TA\vect{v} & = \sum_{i,j}A_{ij}v_iv_j = \sum_{i,j}a(\phi_j, \phi_i)v_i v_j \\
            & = a(\sum_j v_j \phi_j, \sum_i v_i \phi_i) = a(v_h, v_h) \geq \alpha\norm{v_h}^2 > 0
        \end{align*}
    if (\(v_h \neq 0 \Leftrightarrow \vect{v} \neq \vect{0}\)). Hence \(A\) is positive defined.
    \end{proof}
\end{background}
\begin{definition}
    If \(A\) is spd, we define the \textit{A-norm} of \(\vect{v}\) as 
    \begin{align*}
        \norm{v}_A :=& (A\vect{v}, \vect{v})^{\frac{1}{2}}\\
        =& \left(\sum_{i,j}a_{ij} v_i v_j\right)^{\frac{1}{2}}
    \end{align*}
\end{definition}
Since \(A\) is positive defined \(\Rightarrow \text{Re}(\lambda_k(A)) \Rightarrow \lambda_k(A) \neq 0\). Then, by symmetry of \(A\) \(\Rightarrow \lambda_k(A) \in \real\). Combining the two we have that \(A\) sdp \(\Rightarrow \lambda_k (A) > 0 \Rightarrow \exists! \txt{ solution of } A\vect{u} = \vect{f}\)
\begin{definition}
    If \(A\) is sdp, then \(K_2(A) = \frac{\lambda_{\txt{max}}}{\lambda_{\txt{min}}}\) is called \textbf{spectral condition number}
\end{definition}
If \(K_2(A) \gg 1 \Rightarrow A\) is ill-conditioned \(\Rightarrow\) solving \(A\vect{u} = \vect{f}\) is hard.

We can also prove that \(\exists \; C_1, C_2 > 0 : \forall \lambda_h\) eigenvalue of \(A\): 
\[
    \alpha C_1 h^d \leq \lambda_h \leq M C_2 h^{d-2} \qquad d = 1, 2, 3
\]
whence 
\[
    \frac{\lambda_{\txt{max}}(A)}{\lambda_{\txt{min}}(A)} \leq \frac{MC_2}{\alpha C_1} h^{-2}
\]
Then
\[
    K_2(A) = \mathcal{O}(h^{-2})
\]
If we use the conjugate gradient method to solve \(A\vect{u} = \vect{f}\), then:
\[
    \norm{\vect{u}^{(k)} - \vect{u}}_A \leq 2\left(\frac{\sqrt{K_2(A)}+1}{\sqrt{K_2(A)}-1}\right)^k \norm{\vect{u}^{(k)} - \vect{u}}_A
\]
Same with gradient method, with \(K_2(A)\) instead of \(\sqrt{K_2(A)} \Rightarrow\) need for preconditioners.
\subsection{Interpolant estimates}
\begin{equation}
    \norm{u-u_h}_V \leq \frac{M}{\alpha} \inf_{v_h \in V_h} \norm{u-v_h} \underset{\txt{saturation}}{\longrightarrow} 0 \Leftrightarrow \txt{convergence} 
\end{equation}
But how fast it saturates? 

Note: \(\inf_{v_h \in V_h} \norm{u-v_h}_V \leq \norm{u-\bar{u}_h}_V\) \(\forall \; \bar{u}_h\) suitable chosen in \(V_h\) and \(\bar{u}_h\) is a smart guy chosen in a smart way (close enough to \(u\)). 

In \(1\)D the finite element interpolant can be defined as \(\prod_{h}^{r} u(x_k) = u(x_k)\) \(\forall \; x_k\) node. Then \(\bar{u}_h = \prod_{h}^r u \in V_h\). 

How good is \(\bar{u}_h\)? 
\[
    \prod_{h}^{r} u(x) = \sum_{j=1}^{N_h} u(x_j)\phi_j(x)
\]
which is a good approximation.
\subsection*{Interpolant error estimates}
Then, for \(m=0,1\) \(\exists \; C = C(r,m,\hat{k})\) s.t.
\begin{equation}
    \seminorm{v-\prod_{h}^{r}v}{H^m(\Omega)} \leq C\left(\sum_{K \in \mathcal{T}_h}h_K^{2(r+1-m)}\seminorm{v}{H^{r+1}(K)}^2\right)^{\frac{1}{2}} \label{some_estimate_bvp}
\end{equation}
    

where \(h_K = \txt{diam}(K)\) and \(h_K \leq h\) \(\forall \; K\) this yields:
\begin{equation}
    \seminorm{v-\prod_{h}^{r}v}{H^m(\Omega)} \leq C h^{r+1-m}\seminorm{v}{H^{r+1}(K)} \quad \forall \; v \in H^{r+1}(\Omega), m = 0,1 \label{some_other_estimate_bvp}
\end{equation}
Recall also that 
\begin{align*}
    \norm{u-u_h} &= \norm{u-u_h}_{H^1(\Omega)} \\
    &\leq \frac{M}{\alpha} \inf_{v_h \in V_h} \norm{u-v_h} \\
    &\leq \frac{M}{\alpha} \norm{u-\prod_h^r u}_{H^1(\Omega)}
\end{align*}
Using \eqref{some_estimate_bvp} we obtain
\begin{equation}
    \norm{u-u_h} \leq C\frac{M}{\alpha}\left(\sum_{K \in \mathcal{T}_h}h_K^{2r}\seminorm{v}{H^{r+1}(K)}^2\right)^{\frac{1}{2}} \label{first_estimate_H1_bvp}
\end{equation}
Then, by using \eqref{some_other_estimate_bvp}:
\begin{equation}
    \norm{u-u_h} \leq C \frac{M}{\alpha} h^r \seminorm{u}{H^{r+1}(\Omega)} \label{second_estimate_H1_bvp}
\end{equation}

\begin{definition}
    Consider a bilinear form \(a: V \times V \to \real\). The \textit{adjoint} form \(a^*\) is defined as \(a^*:V \times V \to \real\)
    \[
        a^*(v,w) = a(w,v) \quad \forall \; v,w \in V
    \]
\end{definition}
Now let's consider the adjoint problem 
\begin{equation}
    \begin{cases}
        \txt{Find } \phi = \phi(g) \in V & \forall \; g \in L^2(\Omega)\\ 
        a^*(\phi,v) = (g,v) = \int_{\Omega} g v & \forall \; v \in V
    \end{cases}
    \label{Adjoint_problem_bvp}
\end{equation}
Assuming that \(\phi \in H^2(\Omega) \cap V\) (elliptic regularity). Consider now, for example, \(\mathcal{L} = -\Delta\). Then the solution of 
\begin{equation*}
    \begin{cases}
        -\Delta \phi = g & \txt{in } \Omega \\
        u = 0 & \txt{on } \partial \Omega
    \end{cases}
\end{equation*}
satisfies \(\phi \in H^2(\Omega)\). Moreover
\begin{equation}
    \exists \; C_1 > 0 : \norm{\phi(g)}_{H^2(\Omega)} \leq C_1 \norm{g}_{L^2(\Omega)}  \label{L2_norm_bvp}
\end{equation}
    
Take now \(g = e_h = u-u_h\) in \eqref{Adjoint_problem_bvp}. Then
\begin{align*}
    \norm{e_h}^2_{L^2(\Omega)} &= a^*(\phi, e_h) = a(e_h, \phi) \\ 
    &= a(e_h, \phi-\phi_h) \tag{\txt{Galerkin orthogonality}} \\
    &\leq M\norm{e_h}_{H^1(\Omega)}\norm{\phi-\phi_h}_{H^1(\Omega)}
\end{align*}
Take then \(\phi_h = \prod_{h}^{1}\phi\):
\begin{align*}
    \norm{e_h}^2_{L^2(\Omega)} &\leq M\norm{e_h}_{H^1(\Omega)}\norm{\phi - {\textstyle \prod_{h}^{1}}\phi}_{H^1(\Omega)} \\
    &\leq M\honenorm{e_h}C_2 h\seminorm{\phi}{H^2(\Omega)} \tag{for \eqref{some_other_estimate_bvp} with m=r=1} \\
    &\leq M \honenorm{e_h} C_2 h C_1 \ltwonorm{e_h} \tag{for \eqref{L2_norm_bvp}}
\end{align*}
Whence: 
\begin{align*}
    \ltwonorm{e_h} &\leq C_1 C_2 h h \honenorm{e_h} \\
    &\leq M C_1 C_2 h C_3 h^r \seminorm{u}{H^{r+1}(\Omega)} \tag{for \eqref{second_estimate_H1_bvp}}
\end{align*}
So 
\begin{equation}
    \ltwonorm{e_h} \leq \overline{C} h^{r+1} \seminorm{u}{H^{r+1}(\Omega)}
\end{equation}