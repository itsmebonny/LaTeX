\newpage
\section{Spectral Element Method}
\subsection{Introduction}
The problem with the Finite Element Method is that the rate of convergence is limited by the degree of the polynomials used. An alternative can be the Spectral Element Method, for which the convergence rate is limited by the regularity of the solution. 
\subsection{Legendre polynomials}
The Legendre polynomials \(\{L_k(x) \in \mathbb{P}_k, k = 0, 1, \ldots\}\) are the eigenfunctions of the singular Sturm-Liouville problem:
\[
    ((1-x^2)L'_k(x))' + k(k+1)L_k(x) = 0 \quad -1 < x < 1
\]
So they satisfy the recurrence relation
\begin{equation}
    \begin{split}
        &L_0(x) = 1, \ L_1(x) = x, \txt{ and for } k \geq 1 \\
        &L_{k+1}(x) = \frac{2k+1}{k+1}xL_k(x) - \frac{k}{k+1}L_{k-1}(x)
    \end{split}
    \label{legendre_polynomials}
\end{equation}
Given a weight function \(w(x) \equiv 1\), they are mutually orthogonal with respect to it on the interval \((-1, 1)\)
\[
    \int_{-1}^1 L_k(x)L_m(x) \; dx = \begin{cases}
        \frac{2}{2k+1} & \txt{if } k = m \\
        0 & \txt{if } k \neq m
    \end{cases}
\]
The expansion of \(u \in L^2(-1,1)\) in terms of \(L_k\) is 
\[
    u(x) = \sum_{k=0}^{\infty} \hat{u}_k L_(x)
\]
Given that \((f,g) = \int_{-1}^1 fg \, dx\) we know that:
\[
    (u,L_m) = \sum_{k=0} \hat{u}_k (L_k, L_m) \underset{\txt{orth.}}{=} \hat{u}_m\frac{2}{2m+1} \Rightarrow \hat{u}_k = \frac{2k+1}{2} \int_{-1}^1 u L_k \, dx
\]
The truncated Legendre series of \(u\) is the \(L^2-\txt{projection of } u \txt{ over } \mathbb{P}_N\) is 
\begin{equation}
    P_Nu = \sum_{k=0}^{N} \hat{u}_k L_k
\end{equation}
Given any \(u \in H^s(-1,1)\) with \(s \in N\), the projection error \((u-P_Nu)\) satisfies the estimates 
\begin{align*}
    \norm{u-P_Nu}_{L^2(-1,1)} &\leq CN^{-s} \norm{u}_{H^s(-1,1)} & \forall \; s \geq 0 \\
    \norm{u-P_Nu}_{L^2(-1,1)} &\leq CN^{-s} \seminorm{u}{H^s(-1,1)} & \forall \; s \leq N+1 \\
\end{align*}
There is also a ``modified'' Legendre basis for function that vanish at \(\pm 1\). This is because the Legendre basis is not suited to impose Dirichlet B.C.
\begin{align*}
    \psi_0(x) = \frac{1}{2} (L_0(x) - L_1(x)) = \frac{1-x}{2} \\ 
    \psi_N(x) = \frac{1}{2} (L_0(x) + L_1(x)) = \frac{1+x}{2} \\ 
    \psi_{k-1}(x) = \frac{1}{\sqrt{2(2k-1)}} (L_{k-2}(x) - L_k(x))\\ 
    \txt{for } k = 2, \ldots, N \ -1 < x < 1 \\ 
\end{align*}

\subsection{Spectral Galerkin formulation}
Given \(\Omega = (-1, 1), \mu, b, \sigma > 0\) const., \(f: \Omega \to \real\). Look for \(u:\Omega \to \real\) s.t. 
\[
    \begin{cases}
        -(\mu u')'+(bu)' + \sigma u = f & \txt{in } \Omega \\
        u(-1) = 0 \\
        u(1) = 0
    \end{cases}
\]
Set \(V  = H^1_0(\Omega)\), then the weak form of the differential problem reads: 
\[
    \txt{find } u \in V \txt{ s.t } a(u,v) = (f,v)_{L^2(\Omega)} \quad \forall \; v \in V, \ f \in L^2(\Omega)
\]
where 
\begin{align*}
    & a(u,v) = \int_{\Omega} (\mu u' - bu)v'\, dx + \int_{\Omega} \sigma uv \, dx \\
    & (f,v)_{L^2(\Omega)} = \int_{\Omega} f v \, dx
\end{align*}
Now set \(V_N = \mathbb{P}^0_N\) 
\begin{equation}
    \txt{find } u_N \in V_N: a(u_N, v_N) = (f, v_N)_{L^2(\Omega)} \label{weak_spec_galerkin_formulation}
\end{equation}
Now expand \(u_N(x) = \sum_{k=1}^{N-1} \tilde{u}_k \psi_k(x)\) and chose \(v_N = \psi_i(x)\) for any \(i = 1, \ldots, N-1\).
The discretization of the problem reads:
\[
    \txt{find } u = \left[\tilde{u}\right]_{k=1}^{N-1} : \sum_{k=1}^{N-1} a(\phi_k, \psi_i)\tilde{u}_k = (f, \psi_i)_{L^2(\Omega)} \quad \txt{for any } i = 1, \ldots, N-1
\]
Given \(u_N \in V_N\) the solution of the problem, then if \(u \in H^{s+1}(\Omega)\) with \(s \geq 0\), thanks to CeÃ  Lemma, holds that:
\[
    \honenorm{u-u_N} \leq C(s)\left(\frac{1}{N}\right)^s\norm{u}_{H^{s+1}(\Omega)}
\]
So \(u_N\) converges with spectral accuracy with respect to \(N\).
But doing so we would have two full matrices, the stiffness one and the mass one  \(M_{ij} = (\psi_j, \psi_i)_{L^2(-1,1)}\) are quite expensive to compute or invert.

To solve this we can use a Lagrange nodal basis instead of a modal one, by using the Legendre-Gauss-Lobatto quadrature formulas.
In this case we need a Legendre polynomial \(L_N(x)\).

Given a \(L_N(x)\) polynomial, we can put one node at each end of the domain, so \(x_0 = -1, x_N =  1\) and \(x_j = \txt{ zeros of }L'
_N\) with \(j =  1, \ldots, N-1\). We also need a set of weights \(w_j = \frac{2}{N(N+1)} \frac{1}{[L_N(x_j)]^2}\) with \(j = 0, \ldots, N\).

With this set of nodes and weights it's possible to obtain the following interpolatory quadrature formula
\[
    \int_{-1}^1 f(x) \, dx \approx \sum_{j=0}^{N} f(x_j)*w_j
\]
The degree of exactness of this method is \(2N-1\), meaning that 
\[
    \int_{-1}^1 f(x)\,dx = \sum_{j=0}^{N} f(x_j)w_j \quad \forall \; f \in \mathbb{P}_{2N-1}
\]
Some useful operation with LGL nodes
\begin{itemize}
    \item Discrete inner product in \(L^2(-1,1)\):
    \[
        (u,v)_N = \sum_{j=0}^{N} u(x_j)v(x_j)w_j 
    \]
    with degree of exactness \(2N-1\) 
    \[
        (u,v)_{L^2(\Omega)} = (u,v)_N \quad \txt{only if } u, v \in \mathbb{P}_{2N-1}
    \]
    \item Discrete norm in \(L^2(-1,1)\)
    \[
        \norm{u}_N = (u,u)_N^{\frac{1}{2}}
    \]
    with the following norm equivalence: \(\exists \; c_1, c_2 > 0\) s.t.
    \[
        c_1 \norm{v_N}_{L^2(-1,1)} \leq \norm{v_N}_N \leq c_2 \norm{v_N}_{L^2(-1,1)} \quad \forall \; v_N \in \mathbb{P}_N
    \]
\end{itemize}
Given \(\left\{\phi_0, \ldots, \phi_N\right\}\) characteristics Lagrange polynomials in \(\mathbb{P}_N\) w.r.t the LGL nodes. then
\[
    \phi_j = \frac{1}{n(n+1)} \frac{(1-x^2)}{(x_j-x)}\frac{L'_N(x)}{L_N(x_j)} \quad \txt{for } j = 0, \ldots, N
\]
Also true that \(\phi_j(x_k) = \delta_{kj}\) and \(\left\{\phi_j\right\}\) are orthogonal w.r.t. the discrete inner product \((\cdot,\cdot)_N\), meaning that the mass matrix \(M\) is diagonal. Given \(\left\{w_i\right\}\) the set of weights, then 
\[
    M_{ij} = (\phi_j, \phi_i)_N = \delta_{ij}w_i  \quad i,j  = 0, \ldots, N
\]
\subsection{Galerkin with Numerical Integration}
We can now define the spectral Galerkin method with numerical integration (GNI), by setting our bilinear discrete form as \(a_N(u_N, v_N) = (\mu u'_N-b u_n, v'_N)_N+(\sigma u_n, v_n)_N\), and the problem as
\[
    \txt{find } u_N^{\txt{GNI}} \in V_N : a_N(u_N^{\txt{GNI}},v_N)=(f, v_N)_N \quad \forall \; v_N \in V_N
\]
Then, by the same expansion w.r.t. the Lagrange basis: \(u_N^{\txt{GNI}}(x) =  \sum_{i=0}^{N}u_N^{\txt{GNI}}(x_i)\phi_i(x)\) and choose \(v_N(x) = \phi_i(x)\) for any \(i = 1, \ldots, N-1\).  

The GNI discretization of the weak problem reads:
\[
    \txt{look for } u^{\txt{GNI}} = \left[u_N^{\txt{GNI}}(x_j)\right]_{j=0}^N : \begin{cases}
        u_N^{\txt{GNI}}(x_0) = u_N^{\txt{GNI}}(x_N) \\
        \sum_{j=0}^{N} a_N(\phi_j, \phi_i)u_N^{\txt{GNI}} (x_j) = (f, \phi_i)_N & \forall \; i = 1, \ldots, N-1
    \end{cases} 
\]

Now let's have a closer look to the \(\left\{\phi_j\right\}\):
\[
    \phi_j \in \mathbb{P}_N : \phi_j(x_i) = \delta_{ij} = \begin{cases}
        1 & \txt{if } i = j \\
        0 & \txt{otherwise}
    \end{cases}   
\]
Given the discrete inner product \((u,v)_N = \sum_{j=0}^N u(x_j)v(x_j)w_j\) we can write:
\begin{align*}
    (\phi_k, \phi_m)_N &= \sum_{j=0}^{N} \underbrace{\phi_k(x_j)}_{\delta_{kj}} \underbrace{\phi_m(x_j)}_{\delta_{mj}} w_j \quad 0 \leq k,m \leq N \\
    &= \sum_{k=0}^{N} = \begin{cases}
        w_m & \txt{if } k = m \\
        0 & \txt{otherwise}
    \end{cases}
\end{align*}
so \(\left\{\phi_k\right\}\) is orthogonal under the discrete inner product.

The GNI solution is 
\[
    u_N(x) = \sum_{i=0}^{N} \alpha_i\phi_i(x) \quad \left\{\alpha_i\right\} \txt{ unknown coefficients}
\]
Set now \(x = x_j\) with LGL nodes:
\[
    u_N(x_j) = \sum_{i=0}^{N} \alpha_i \underbrace{\phi_i(x_j)}_{\delta{ij}} = \alpha_j
\]
So, given \(u_n^{\txt{GNI}}(x_j)\) the nodal values, we obtain the nodal expansion:
\[
    u_N^{\txt{GNI}}(x) = \sum_{j=0}^{N} u_N^{\txt{GNI}} (x_j)\phi_j(x)
\]
\subsection*{Algebraic form of Spectral GNI}
Now it's about solving the following linear system 
\[
    A^{\txt{GNI}}\vect{u}^{\txt{GNI}} = \vect{f}^{\txt{GNI}}
\]
with \(A_{ij}^{\txt{GNI}} = a_N(\phi_j, \phi_i)\) for \(i = 1,\ldots, N-1, j = 0, \ldots, N\) and \(\vect{f}^{\txt{GNI}} = (f,\phi_i)_N\) for \(i = 1, \ldots, N-1\):
\[
    A^{\txt{GNI}} = \left[\begin{matrix*}
        1 & 0 & \cdots & 0 & 0 \\
        \vdots & \ddots & & &\vdots\\
        \vdots & & a_N(\phi_j, \phi_i) & & \vdots \\
        \vdots & & & \ddots & \vdots \\
        0 & 0 & \cdots & 0 & 1
    \end{matrix*}\right], \quad \vect{f}^{\txt{GNI}} = \left[\begin{matrix*}
        0 \\ \vdots \\ f_i^{\txt{GNI}} \\ \vdots \\ 0
    \end{matrix*}\right]
\]
Given that \(a(u,v) = \int_{-1}^1 \mu u' v' - \int_{-1}^1 bu v' + \int_{-1}^1 \sigma u v\) and \((f,v) = \int_{-1}^1 fv\). We estabilished that \(a_n(u,v) = (\mu u', v')_N - (bu,v')_N + (\sigma u, v)_N\) and that \((f,v)_N = (f,v)_N\), so we obtain 
\[
    A_{ij}^{\txt{GNI}} = a_N(\phi_j, \phi_i) = \underbrace{\left(\mu \phi_j', \phi_i'\right)_N}_{\txt{A}} - \underbrace{\left(b\phi_j, \phi_i'\right)_N}_{\txt{B}}+\underbrace{\left(\sigma \phi_j, \phi_i\right)_N}_{\txt{C}}
\]
Assuming \(\mu, b, \sigma \in \real\) we have that 
\begin{align*}
    C&: \sigma(\phi_j, \phi_i)_N = \sigma \delta_{ij} w_i = \begin{cases}
        \sigma w_i & i = j \\
        0 & i\neq j
    \end{cases} &\rightarrow &\quad M = \sigma \underbrace{\left[\begin{matrix}
        w_0 & 0 & 0 \\ 
        0 & \ddots & 0 \\
        0 & 0 & w_N
    \end{matrix}\right]}_{\txt{diagonal weight matrix}} \\
    B&: - b(\phi_j, \phi_i')_N = -b\sum_{k=0}^{N} \underbrace{\phi_j(x_k)}_{\delta_{jk}}\underbrace{\phi_i'(x_k)}_{D_{ki}\neq 0} w_k &\rightarrow& \quad \txt{full matrix} \\ 
    A&: \mu(\phi_j', \phi_i')_N = \mu\sum_{k=0}^{N} \underbrace{\phi_j'(x_k)}_{D_{kj}}\underbrace{\phi_i'(x_k)}_{D_{ki}} w_k &\rightarrow& \quad \txt{full matrix}
\end{align*}
where \(D = (D_{ki}) = \phi_k'(x_i)\) is the differentiation matrix that can be computed only once. The computation of \((f,\phi_i)_N\) can be made this way 
\[
    (f, \phi_i)_N = \sum_m w_m f(x_m)\underbrace{\phi_i(x_m)}_{\delta_{im}} = w_i f(x_i) 
\]
In conclusion the GNI method is still as full as the spectral one, but much easier to compute thanks to the nodal expansion.
\subsection*{Accuracy}
We can define the Global Lagrange polynomial of degree \(N\) that interpolates \(u\) at LGL nodes as:
\[
    I_nu(x) = \sum_{j=0}^{N}u(x_j)\phi_j(x)
\]
And the interpolation error, for any \(u \in H^{s+1}(-1, 1)\) with \(s \geq 0 \), the interpolation error \(u - I_N u\) satisfies the estimate:
\[
    \norm{u-I_Nu}_{H^k(-1,1)} \leq C(s)\left(\frac{1}{N}\right)^{s+1-k}\norm{u}_{H^{s+1}(-1,1)} \quad \txt{for }k = 0,1
\]
One important feature of LGL nodes is that they are not uniformly spaced (otherwise there could be problems), so that 
\[
    I_nu(x_k) = u(x_k) \quad 0 \leq k \leq N
\]
It's also possible to estimate the \(L^2\) norm of the error as:
\[
    \norm{u - I_N u}_{L^2(-1,1)} \leq C(s) \left(\frac{1}{N}\right)^{s+1} \norm{u}_{H^{s+1}(-1,1)} \quad s \geq 1
\]
\begin{theorem}[Quadrature error]
    \(\exists \; c > 0 : \forall \; f \in H^q(-1,1)\), with \(q \geq 1\), \(\forall \; v_N \in \mathbb{P}_N\) it holds 
    \[
        \abs{\int_{-1}^1 f v_N \, dx - (f, v_N)_N} \geq c \left(\frac{1}{N}\right)^q \norm{f}_{H^q(-1,1)} \norm{v_N}_{L^2(-1,1)}
    \]
\end{theorem}
Let now \(u_N^{\txt{GNI}} \in V_N\) be the solution of
\[
     a_N(u_N^{\txt{GNI}}, v_N) = (f, v_N)_N \quad \forall \; v_N \in V_N
\]
If \(u \in H^{s+1}(\Omega)\) and \(f \in H^{s}(\Omega)\) with \(s \geq 0\), then:
\[
    \norm{u-u_N^{\txt{GNI}}}_{H^1(\Omega)} \leq C(s) \left(\frac{1}{N}\right)^s \left(\norm{u}_{H^{s+1}(\Omega)}+\norm{f}_{H^s(\Omega)}\right)
\]
So \(u_N^{\txt{GNI}}\) converges with spectral accuracy w.r.t. to \(N\) to the exact solution when the latter is smooth.

\subsubsection*{General ideas}
The idea proposed until now are the following:
\[
    \begin{array}{lccc}
        \txt{(WP)} & V \txt{ Hilbert} & a \txt{ bilinear form} & F \txt{ functional} \\ 
        \txt{(SG)} & V_h \txt{ instead of } V & \txt{same }a &  \txt{same } F \\ 
        \txt{(GNI)} & V_N & a_N  & F_N\\ 
    \end{array}
\]
\begin{itemize}
    \item For the Galerkin method one can use CeÃ  Lemma 
    \begin{align*}
        \honenorm{u-u_N} &\leq \underbrace{\inf_{v_N \in V_N}\honenorm{u-v_N}}_{\txt{distance of } V \txt{ from }V_N} \\
        &\leq \honenorm{u-I_nu}
    \end{align*}
    \item For the Galerkin with Numerical Integration we need something more:
    \begin{align*}
        \honenorm{u-u_N} \leq\quad & \txt{``distance'' of } V \txt{ from }V_N \\
        &+ \txt{``distance'' of } a(\cdot,\cdot) \txt{ from }a_N(\cdot,\cdot) \\
        &+ \txt{``distance'' of } F(\cdot) \txt{ from }F_N(\cdot)
    \end{align*}
\end{itemize}
\subsection{Strang Lemma}
\begin{lemma}[Strang lemma]
Consider the problem
\begin{equation}
    \txt{find } u \in V: a(u,v) = F(v) \quad \forall \; v \in V
    \label{another_weak_formulation}
\end{equation}
and its approximation 
\begin{equation}
    \txt{find } u_h \in V_h: a_h(u_h,v_h) = F_h(v_h) \quad \forall \; v_h \in V_h
    \label{another_weak_approximation}
\end{equation}
with \(\left\{V_h\right\}\) being a family of subspaces of \(V\). Suppose that \(a_h(\cdot,\cdot)\) is continuous on \(V_h \times V_h\) and uniformly coercive on \(V_h\) meaning that:
\[
    \exists \; \alpha^* > 0 \txt{ independent of }h : a_h(v_h, v_h) \geq \alpha^* \norm{v_h}^2_V \quad \forall \; v_h \in V_h
\]
Also suppose that \(F_h\) is linear and bounded on \(V_h\). Then:
\begin{itemize}
    \item exist a unique solution \(u_h\) to the problem.
    \item such solution depends continuously on the data, i.e. we have 
    \[
        \norm{u_h}_V \leq \frac{1}{\alpha^*} \sup_{v_h \in V_h \backslash \left\{0\right\}} \frac{F_h(v_h)}{\norm{v_h}_V}
    \]
    \item  finally, the following a priori error estimate holds 
    \begin{align*}
        \norm{u-u_h}_V \quad \leq & \inf_{w_h \in V_h} \bigg\{\left(1+\frac{M}{\alpha^*}\right) \norm{u-w_h}_V \\
        &+ \frac{1}{\alpha^*} \sup_{v_h \in V_h \backslash \left\{0\right\}} \frac{\abs{a(w_h, v_h) - a_h(w_h, v_h)}}{\norm{v_h}_V} \bigg\} \\
        &+ \frac{1}{\alpha^*} \sup_{v_h \in V_h \backslash \left\{0\right\}} \frac{\abs{F(v_h)-F_h(v_h)}}{\norm{v_h}_V} 
    \end{align*}
\end{itemize}
with \(M\) being the continuity constant of \(a(\cdot, \cdot)\)
\end{lemma}
\begin{proof}
    The assumption of Lax-Milgram are satisfied for \eqref{another_weak_approximation}, so the solution exists and is unique. Moreover
    \[
        \norm{u_h}_V \leq \frac{1}{\alpha^*} \norm{F_h}_{V'_h} 
    \]
    with \(\norm{F_h}_{V'_h} = \sup_{v_h \in V_h \backslash \left\{0\right\}} \frac{F_h(v_h)}{\norm{v_h}_V}\) being the norm of the dual space \(V'_h\).

    Now the only thing missing is the error inequality. Let \(w_h\) be any function of the subspace \(V_h\). Setting \(\sigma_h = u_h -w_h \in V_h\), we have:
    \begin{align*}
        \alpha^* \norm{\sigma_h}^2_V &\leq a_h(\sigma_h, \sigma_h) \tag*{(by coercivity of \(a_h\))} \\
        &= a_h(u_h, \sigma_h) - a_h(w_h, \sigma_h) \\
        &= F_h(\sigma_h) - a_h(w_h, \sigma_h) \tag*{(by \eqref{another_weak_approximation})} \\
        &= F_h(\sigma_h) - F(\sigma_h) + F(\sigma_h) - a_h(w_h, \sigma_h) \\
        &= \left[F_h(\sigma_h)-F(\sigma_h)\right] + a(u, \sigma_h) - a_h(w_h, \sigma_h) \tag*{(by \eqref{another_weak_formulation})} \\
        &= \left[F_h(\sigma_h) - F(\sigma_h)\right] + a(u-w_h, \sigma_h) + \left[a(w_h, \sigma_h) - a_h(w_h, \sigma_h)\right]
    \end{align*}
    If \(\sigma_h \neq 0\), we can divide everything by \(\alpha^*\norm{\sigma_h}_V\)
    \begin{align*}
        \norm{\sigma_h}_V &\leq \frac{1}{\alpha^*} \left\{\frac{\abs{F_h(\sigma) - F(\sigma_h)}}{\norm{\sigma_h}_V} + \frac{\abs{a(u-w_h,\sigma_h)}}{\norm{\sigma_h}_v} + \frac{\abs{a(w_h, \sigma_h) - a_h(w_h, \sigma_h)}}{\norm{\sigma_h}_V}\right\} \\
        &\leq \frac{1}{\alpha^*} \left\{M\norm{u-w_h}_V + \sup_{\mathclap{v_h \in V_h \backslash \left\{0\right\}}} \frac{\abs{a(w_h, v_h) - a_h(w_h, v_h)}}{\norm{v_h}_V} + \sup_{\mathclap{v_h \in V_h \backslash \left\{0\right\}}}\frac{\abs{F_h(\sigma_h)-F(\sigma_h)}}{\norm{v_h}_V}\right\}
    \end{align*}
    Clearly, if \(\sigma_h = 0\), the inequality still holds.

    We can now estimate the error between \(u\) and \(u_h\). Since \(u-u_h = (u-w_h) - \sigma_h\) we obtain
    \begin{align*}
        \norm{u-u_h} &\leq  \norm{u-w_h}_V + \norm{\sigma_h}_V \\
        &\leq \norm{u-w_h}_V + \frac{1}{\alpha^*} \bigg\{M\norm{u-w_h}_V + \sup_{\mathclap{v_h \in V_h \backslash \left\{0\right\}}} \frac{\abs{a(w_h, v_h) - a_h(w_h, v_h)}}{\norm{v_h}_V}  \\
        & \quad + \sup_{\mathclap{v_h \in V_h \backslash \left\{0\right\}}} \frac{\abs{F_h(\sigma_h)-F(\sigma_h)}}{\norm{v_h}_V}\bigg\} \\
        &= \left(1+\frac{M}{\alpha^*}\right)\norm{u-w_h}_V + \frac{1}{\alpha^*} \sup_{v_h \in V_h \backslash \left\{0\right\}} \frac{\abs{a(w_h, v_h) - a_h(w_h, v_h)}}{\norm{v_h}_V} \\
        &\quad + \sup_{v_h \in V_h \backslash \left\{0\right\}}\frac{\abs{F_h(\sigma_h)-F(\sigma_h)}}{\norm{v_h}_V}
    \end{align*}
    If this inequality holds \(\forall \; w_h \in V_h\), then it holds when taking the infimum.
\end{proof}
Now we should try to apply Strang's lemma to GNI method in one dimension, to verify its convergence. Obviously, we will have \(V_N\) instead of \(V_h\) and everything that follows from there.

First of all, the error of the LGL numerical integration formula 
\[
    E(g, v_N) = (g, v_N) - (g, v_N)_N
\]
with \(g\) and \(v_N\) being a generic continuous function and a generic polynomial of \(\mathbb{Q}_N\) respectively. Introducing the interpolation polynomial \(I_Ng\), we obtain:
\begin{align*}
    E(g, v_n) &= (g, v_N) - (I_Ng, v_N) \\
    &= (g, v_N) - (I_{N-1}g, v_N) + \underbrace{(\overbrace{I_{N-1}g}^{\in \mathbb{Q}_{N-1}}, \overbrace{v_N}^{\in \mathbb{Q}_N})}_{\in \mathbb{Q}_{2N-1}} \\
    &= (g, v_N) - (I_{N-1}g, v_N) +(I_{N-1}g, v_N)_N - (I_{N}g, v_N)_N \\
    &= (g - I_{N-1}g, v_N) + (I_{N-1}g - I_N g, v_N)_N
\end{align*}
The first summand of the right-hand side can be bounded from above using Cauchy-Schwartz:
\[
    \abs{(g-I_{N-1}g, v_N)} \leq \norm{g-I_{N-1}g}_{L^2(-1,1)}\norm{v_N}_{L^2(-1,1)}
\]
For the second term, it's a bit more difficult, we need to introduce two new lemmas
\begin{lemma}
    The discrete scalar product \((\cdot, \cdot)_N\) is a scalar product on \(\mathbb{Q}_N\) and, as such, it satisfies the Cauchy-Schwartz inequality
    \[
        \abs{(\phi, \psi)_N} \leq \norm{\phi}_N \norm{\psi}_N
    \]
    where the discrete norm is defined as 
    \[
        \norm{\phi}_N = \sqrt{(\phi, \phi)_N} \quad \forall \; \phi \in \mathbb{Q}_N
    \]
\end{lemma}
\begin{lemma}
    The ``continuous'' norm of \(L^"(-1,1)\) and the ``discrete'' norm \(\norm{\cdot}_N\) verify the inequalities
    \[
        \norm{v_N}_{L^2(-1,1)} \leq \norm{v_N}_N \leq \sqrt{3}\norm{v_N}_{L^2(-1,1)}
    \]
    hence they are uniformly equivalent on \(\mathbb{Q}_N\)
\end{lemma}
By using these two lemmas we are able to obtain 
\begin{equation*}
    \begin{split}
        &\abs{(I_{N-1}g - I_Ng, v_N)_N} \leq \norm{I_{N-1}g - I_Ng}_N \norm{v_N}_N  \\
        &\leq 3 \left[\norm{I_{N-1}g-g}_{L^2(-1,1)} + \norm{I_{N}g-g}_{L^2(-1,1)}\right] \norm{v_N}_{L^2(-1,1)}
    \end{split}
\end{equation*}
Putting all together we obtain the upper bound 
\[
    \abs{E(g,v_N)} \leq \left[4\norm{I_{N-1}g-g}_{L^2(-1,1)} + 3 \norm{I_{N-1}g-g}_{L^2(-1,1)} \right] \norm{v_N}_{L^2(-1,1)}
\]
Using then the interpolation estimate 
\[
    \norm{f- I_Nf}_{H^k(-1,1)} \leq C(s)\left(\frac{1}{N}\right)^{s-k} \norm{f}_{H^s(-1,1)} \quad s \geq 1, k = 0,1
\]
we can bound \(\abs{E(g,v_N)}\) even more
\[
    \abs{E(g,v_N)} \leq C(s)\left[\left(\frac{1}{N-1}\right)^s + \left(\frac{1}{N}\right)^s\right] \norm{g}_{H^s(-1,1)} \norm{v_N}_{L^2(-1,1)}
\]
assuming that \(g \in H^s(-1,1)\).

Then, since for each \(N\geq 2 \txt{ we have that }\frac{1}{N-1} \leq \frac{2}{N}\), the error for the LGL integration can be written as 
\[
    \abs{E(g,v_N)} \leq C(s)\left(\frac{1}{N}\right)^s \norm{g}_{H^s(-1,1)} \norm{v_N}_{L^2(-1,1)}
\]

\subsection{GNI as Collocation method}
Let us introduce a problem 
\[
    \begin{cases}
        Lu = -(\mu u')' + (bu)' + \sigma u =  f & -1 < x < 1 \\
        u(-1) = u(1) = 0
    \end{cases}
\]
that has the usual weak formulation 
\[
    \txt{find } u \in V = H^1_0(-1,1): a(u,v) = F(v), \forall \; v \in V
\]
The GNI formulation follows 
\[
    \begin{cases}
        \txt{find } u_N \in V_N = \mathbb{P}^0_N = \left\{v_N  \in \mathbb{P}_N : v_N(\pm 1) = 0\right\} \\
        a_N(u_N, v_N) = F_N(v_N) \quad \forall \; v_N \in V_N
    \end{cases}
\]
Note that, thanks to the exactness of LGL quadrature formula 
\begin{align*}
    a_N(u_N, v_N) &\overset{(\txt{def. of }I_N)}{=} (I_N\underbrace{(\mu u'_N - bu_N)}_{\in \mathbb{P}_N}, \underbrace{v'_N}_{\in \mathbb{P}_{N-1}})_N + (\sigma u_N, v_N)_N \\
    &\overset{(\txt{exactness})}{=} (I_N(\mu u' - b u), v_N) + (\sigma u_N, v_N)_N \\
    &\overset{(\txt{int. by parts})}{=} -(\underbrace{I_N(\mu u' - b u)'}_{\in \mathbb{P}_{N-1}}, \underbrace{v_N}_{\in \mathbb{P}_N}) + (\sigma u_N, v_N)_N \\
    &\overset{(\txt{exactness})}{=} (\underbrace{-(I_N(\mu u' - b u_N))' + \sigma u_N}_{= L_Nu_N}, v_N)_N
\end{align*}
So it's obvious that \((\txt{GNI}) \iff (L_Nu_N, v_N)_N = F_N(v_N) \ \forall \; v_N \in V_N\), so it's a collocation method.
\subsection{1D Spectral Elements}
Let \(p \geq 1\) integer and \(\mathbb{P}_p\) the space of polynomials of degree \(\leq p\). We can divide the domain \(\Omega = \bigcup_{n=1}^{N_e} I_k\) with \(I_k\) disjoint elements s.t. \(I_k = F_k ((-1,1))\) and 
\[
    F_k : \xi \mapsto x = \frac{b_k -a_k}{2}\xi + \frac{b_k+a_k}{2}
\]
with \(N_p = p\cdot N_e +1\) the total number of nodes in \(\Omega\). 
Then we use the Lagrange basis functions \(\left\{ \phi_i\right\}_{i=1}^{N_p}\) w.r.t. the LGL nodes.

Now set \(X_\delta = \left\{ v \in \mathcal{C}^0 : v\vert_{I_k} \in \mathbb{P}_p, \forall \; I_k \right\}\) with \(h_k = meas(I_k)\), mesh size \(h =  max_k h_k\) and polynomial degree \(p\) we can define \(\delta = (h,p)\) and 
\[
    v_\delta(x) = \sum_{i=1}^{N_p} v_\delta (x_i)\phi_i(x) \quad \forall \; v_\delta \in X_\delta
\]
Let now \((\hat{\xi}_j, \hat{w}_j) \txt{ for } j = 0, \ldots, p\) be the LGL nodes and respective weights in \(\hat{\Omega} = (-1,1)\).
We can define the local LGL quadrature as
\[
    \int_{I_k} u(x)v(x) \, dx \approx (u,v)_{\delta, I_k} = \sum_{j=0}^{p} u(\xi_j)v(\xi_j)w_j
\]
with \(\xi_j = \frac{b_k - a_k}{2}\hat{\xi}_j + \frac{b_k + a_k}{2}\) and \(w_j = \frac{b_k -a_k}{2}\hat{w}_j\).
Meanwhile we can pass this quadrature to the whole domain, obtaining the composite LGL quadrature:
\[
    \int_\Omega u(x)v(x)\, dx \approx (u,v)_{\delta, \Omega} = \sum_{k=1}^{N_e} (u,v)_{\delta, I_k}
\]
with its relative error \(\exists \; c > 0 : \forall \; f \in H^r(\Omega), r\geq 1, p \geq 1 : \forall \; v_\delta \in X_\delta \):
\[
    \abs{\int_{\Omega} fv_\delta \, dx - (f, v_\delta)_{\delta, \Omega}} \leq c h^{\min(p,r)}\left( \frac{1}{p} \right)^r \norm{f}_{H^r(\Omega)}\norm{v_\delta}_{L^2(\Omega)}
\]
and its interpolation error as: \(\exists \; c > 0 : \forall \;\in H^{s+1}(\Omega), s \geq 1\)
\[
    \norm{v - {\textstyle \prod_{\delta}^{LGL}}v}_{H^k(\Omega)} \leq Ch^{\min(p+1, s+1)-k}\left( \frac{1}{p} \right)^{s+1-k}\norm{v}_{H^{s+1}(\Omega)}
\] 
\subsection{Spectral Element Method with Numerical Integration}
Let's go back to the problem 
\[
    \begin{cases}
        -(\mu u')' - (bu)' + \sigma u = f & \txt{in }  \Omega \\
        u(a) = u(b) = 0
    \end{cases}
\]
Given \(V = H^1_0(\Omega)\), the weak formulation reads
\[
    \txt{find }u \in V : a(u,v) = (f,v)_{L^2(\Omega)} \quad \forall \; v \in V, f \in L^2(\Omega)
\]
with 
\begin{flalign*}
    &a(u,v) = \int_\Omega (\mu u' - bu)v' \, dx + \int_\Omega \sigma uv \, dx \\
    &(f,v)_{L^2(\Omega)} = \int_\Omega fv \, dx 
\end{flalign*}
Now set \(a_\delta(\phi_j, \phi_i) = (\mu \phi'_j- b\phi_j, \phi_i)_{\delta, \Omega} + (\sigma \phi_j, \phi_i)_{\delta, \Omega}\) to get the SEM-GNI formulation:
\begin{equation}
    \txt{find }u_\delta^{\txt{GNI}} \in V_\delta : a_\delta(u_\delta^{\txt{GNI}}, v_\delta) = (f,v_\delta)_{\delta, \Omega} \quad \forall \; v_\delta \in V_\delta
\end{equation}
Now expand \(u_\delta^{\txt{GNI}}\) w.r.t the Lagrange basis \(u_\delta^{\txt{GNI}}(x) = \sum_{i=1}^{N_p}u_\delta^{\txt{GNI}}(x_i)\phi_i(x)\) adn choose \(v_\delta(x) = \phi_i(x)\) for any \(i = 1, \ldots, N_p\). We can now write the SEM-GNI discretization of the weak formulation:
\[
    \begin{cases}
        \txt{find } u^{\txt{GNI}} = \left[ u_\delta^{\txt{GNI}}(x_j) \right]_{j=1}^{N_p} \\
        u_\delta^{\txt{GNI}}(x_1) = u_\delta^{\txt{GNI}}(x_{N_p}) = 0 \\
        \sum_{j=1}^{N_p} a_\delta(\phi_j, \phi_i)u_\delta^{\txt{GNI}}(x_j) = (f, \phi_i)_{\delta, \Omega} & \forall \; i = 1, \ldots, N_p
    \end{cases}
\]
or, in algebraic form \(A^{\txt{GNI}}u^{\txt{GNI}} = f^{\txt{GNI}}\) with \(A_{ij}^{\txt{GNI}} = a_\delta(\phi_j,\phi_i)\) and \(f_i^{\txt{GNI}} = (f,\phi_i)_{\delta, \Omega}\).

Now, for the error analysis, we will apply the Strang lemma, so:
\begin{align*}
    \norm{u- u _\delta^{\txt{GNI}}}_V \leq \ & \norm{u-u_\delta}_V \\
    & + \frac{1}{\mu^*} \sup_{v_\delta \in V_\delta \backslash\left\{ 0 \right\}} \frac{\abs{a(u_\delta, v_\delta) - a_\delta(u_\delta, v_\delta)}}{\norm{v_\delta}_V} \\
    & + \frac{1}{\mu^*} \sup_{v_\delta \in V_\delta \backslash\left\{ 0 \right\}} \frac{\abs{f,v_\delta}_{L^2(\Omega) - (f,v_\delta)_{\delta,\Omega}}}{\norm{v_\delta}_V}
\end{align*}
where \(\mu^*\) is the coercivity constant of \(a_\delta\): \(a_\delta(v_\delta, v_\delta) \geq \mu^*\norm{v_\delta}^"_V\) and \(u_\delta\) the SEM-GNI solution.
Thus for any \(u \in H^{s+1}(\Omega)\) and \(f \in H^r(\Omega)\) 
\[
    \norm{u-u_\delta^{\txt{GNI}}}_{H^1(\Omega)} \leq C\left[ h^{\min(p,s)}\left( \frac{1}{p} \right)^s \norm{u}_{H^{s+1}(\Omega)} + h^{\min(p,r)}\left( \frac{1}{p} \right)^r \norm{f}_{H^{r}(\Omega)}  \right]
\]
So \(u_\delta^{\txt{GNI}}\) converges with spectral accuracy w.r.t. \(p\) and algebraic accuracy w.r.t. \(h\) to the exact solution.
\subsection{Convergence rate of SEM-GNI}
When \(s,r\) are large \((s, r > p)\):
\[
    \norm{u-u_\delta}_{H^1{\Omega}} \leq C \left[ h^p \left(\frac{1}{p}\right)^s \norm{u}_{H^{s+1}(\Omega)} + h^p \left(\frac{1}{p}\right)^r \norm{f}_{H^{r}(\Omega)}  \right]
\]
when \(s\) is small \((s \leq p)\):
\[
    \norm{u-u_\delta}_{H^1(\Omega)} \leq C\left( \frac{h}{p} \right)^s \norm{u}_{H^{s+1}(\Omega)}
\]
