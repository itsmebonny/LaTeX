\newpage
\section{Parabolic equations}
\subsection{Introduction}
Now we consider parabolic equations of the form
\begin{equation}
    \partialderivative{u}{t} + \loperator u = f \quad \vect{x} \in \Omega, t>0
    \label{example_problem_pbl}
\end{equation}
where: 
\begin{itemize}
    \item \(\Omega\) is a domain of \(\real^d\) with \(d = 1,2,3\)
    \item \(f = f(\vect{x}, t)\) is a given function 
    \item \(\loperator = \loperator (\vect{x})\) is a generic elliptic operator acting on \(u = u(\vect{x}, t)\)
\end{itemize}
When solved for a bounded time interval, for example \(0 < t < T\), the region \(Q_T = \Omega \times (0,T)\) is called cylinder in the space \(\real^d \times \real^+\). 
In \eqref{example_problem_pbl} must be assigned an initial condition 
\begin{equation}
    u(\vect{x}, 0) = u_0(\vect{x}),\quad \xvec \in \Omega
    \label{initial_cond_pbl}
\end{equation}
also we'll need some BC, like 
\begin{equation}
    \begin{aligned}
        u(\xvec, t) &= \phi(\xvec, t) & \xvec \in \Gamma_D \txt{ and } t > 0 \\
        \partialderivative{u(\xvec, t)}{n} &=\psi(\xvec, t) & \xvec \in \Gamma_N \txt{ and } t > 0 
    \end{aligned}
    \label{BC_example_pbl}
\end{equation}
where \(u_0, \phi\) and \(\psi\) are given funcion and \(\left\{ \Gamma_D, \Gamma_N \right\}\) provides a boundary partition that is \(\Gamma_D \cup \Gamma_N = \boundary, \interior{\Gamma_D} \cap \interior{\Gamma_N} = \emptyset\). For obvious reasons \(\Gamma_D\) is the Dirichlet boundary, while \(\Gamma_N\) is the Neumann one.

In the one dimensional case the problem becomes 
\begin{equation}
    \begin{aligned}
        &\partialderivative{u}{t} - \nu \partialderivative{^2u}{x^2} = f & 0 < x <d, t> 0 \\
        &u(x,0) = u_0(x) & 0 < x < d \\
        & u(0,t) = u(d,t) = 0 & t>0
    \end{aligned}
    \label{one_dim_pbl}
\end{equation}
which describes the evolution of the temperature \(u(x,t)\) at point \(x\) and time \(t\) of a metal bar of length \(d\) occupying the interval \([0,d]\), whose thermal conductivity is \(\nu\) and whose endpoints are kept at a constant temperature of zero degrees. The function \(u_0\) describes the temperature in the initial state, while \(f\) represents the heat generated per unit of length by the bar. This is called the heat equation.
\subsection{Weak formulation and approximation}
We proceed as usual by multiplying for each \(t>0\) the differential equation by a test function \(v = v(\xvec)\) and integrating. We set \(V = H^1_{\Gamma_D}(\Omega)\) and, for each \(t>0\), we seek \(u(t)\in V\) s.t. 
\begin{equation}
    \int_{\Omega} \partialderivative{u(t)}{t} v \, d\Omega + a(u(t), v) = \int_\Omega f(t)v \, d\Omega \quad \forall \; v \in V 
    \label{weak_formulation_heat_pbl}
\end{equation}
where 
\begin{itemize}
    \item \(u(0) = u_0\)
    \item \(a(\cdot,\cdot)\) is the bilinear form associated to the operator \(\loperator\)
    \item we have supposed for simplicity \(\phi=0\) and \(\psi=0\)
\end{itemize}
\begin{definition}
    A bilinear form \(a(\cdot, \cdot)\) is said weakly coercive if 
    \[
        \exists \; \lambda \geq 0, \exists \; \alpha > 0 : a(v,v) + \lambda \norm{v}^2_{L^2(\Omega)} \geq \alpha \norm{v}^2_V \quad \forall \; v \in V
    \]
\end{definition}
Rationale for weak coercivity 
\[
    \partialderivative{u}{t} +\loperator u = f 
\]
now we perform a change of variable \((u = e^{\lambda t})\)
\[
    \partialderivative{w}{t} + \loperator w + \lambda w = e^{-\lambda t} f
\]
so that the bilinear form 
\[
    \tilde{a}(w,v) := a(w,v)+\lambda(w,v)_{L^2(\Omega)} \Rightarrow \tilde{a}(w,w) := a(w,w) + \lambda \ltwonorm{w}^2
\]
\begin{theorem}
    Suppose that the bilinear form \(a(\cdot,\cdot)\) is continuous and weakly coercive. Moreover, we require \(u_0 \in L^2(\Omega)\) and \(f \in L^2(Q_T)\)- Then, \eqref{weak_formulation_heat_pbl} admits a unique solution \(u \in \mathcal{C}^0 (\real^+;L^2(\Omega))\). Also, \(u \in L^2(\real^+;V)\) and \(\partialderivative{u}{t} \in L^2(\real^+; V')\).
\end{theorem}
\subsection{Algebraic formulation}
Now we can use Galerkin to approximate, for each \(t > 0\), we need to find \(u_h(t) \in V_h\) s.t. 
\begin{equation}
    \int_\Omega \partialderivative{u_h(t)}{t} v_h \, d\Omega + a(u_h(t), v_h) = \int_\Omega f(t)v_h \, d\Omega \quad \forall \; v_h \in V_h
\label{semi-discretization_pbl}
\end{equation}
with \(u_h(0) = u_{0h}\), where \(V_h \subset V\) is a suitable space of finite dimension and \(u_{0h}\) is a convenient approximation of \(u_0\) in the space \(V_h\).

Now we need to discretize the temporal variable, because, as of now, we obtained a semi-discretization of the problem.

We introduce a basis \(\left\{ \phi_j \right\}\) for \(V_h\) and we observe that it suffices that \eqref{semi-discretization_pbl} is verified for the basis function in order to be satisfied by all the functions in the subspace. 

Moreover, since for each \(t > 0\), the solution to the Galerkin problem belongs to the subspace as well, we will have
\[
    u_h(\xvec, t) = \sum_{j=1}^{N_h} u_j(t)\phi_j(\xvec)
\]
where the coefficients \(\left\{ u_j(t) \right\}\) represent the unknown of the problem. 

Denoting by \(\dot{u}_j(t)\) the temporal derivatives of \(u_j(t)\), \eqref{semi-discretization_pbl} becomes
\[
    \int_\Omega \sum_{j=1}^{N_h} \dot{u}_j(t) \phi_j\phi_i \, d\Omega + a\left( \sum_{j=1}^{N_h} u_j(t)\phi_j, \phi_i \right) = \int_\Omega f(t)\phi_i \, d\Omega, \quad i = 1,2,\ldots, N_h
\]
that is 
\begin{equation}
    \sum_{j=1}^{N_h} \dot{u}_j(t) \underbrace{\int_\Omega \phi_j \phi_i \, d\Omega}_{m_{ij}} + \sum_{j=1}^{N_h} u_j(t) \underbrace{a(\phi_j, \phi_i)}_{a_{ij}} = \underbrace{\int_\Omega f(t)\phi_i \, d\Omega} \quad i = 1,2,\ldots, N_h
    \label{algebraic_formulation_pbl}
\end{equation}
If we define the vector of unknowns \(\vect{u} = (u_1(t), u_2(t), \ldots, u_{N_h}(t))^T\), the mass matrix \(M = [m_{ij}]\), the stiffness matrix \(A = [a_{ij}]\) and the right hand side vector \(\vect{f} = (f_1(t), f_2(t), \ldots, f_{N_h}(t))^T\), the system \eqref{algebraic_formulation_pbl} can be rewritten as 
\[
    M\dot{\vect{u}}(t) + A\vect{u}(t) = \vect{f}(t)
\]
\subsection{Time discretization}
For the numerical solution of this ODE system we will use the \(\theta-\)method, which discretizes the temporal difference quotient and replaces the other terms with a linear combination of the value at time \(t^k\) and of the value at time \(t^{k+1}\), depending on the real parameter \(0 \leq \theta \leq 1\).
\begin{equation}
    M\frac{\vect{u}^{k+1} - \vect{u}^k}{\Delta t} + A[\theta \vect{u}^{k+1} + (1-\theta)\vect{u}^k] = \theta \vect{f}^{k+1} + (1-\theta)\vect{f}^k
    \label{theta_method_pbl}
\end{equation}
The real positive parameter \(\Delta t = t^{k+1}-t^k\), \(k=0,1,\ldots\) denotes the discretization step.

Some particular cases of \eqref{algebraic_formulation_pbl} 
\begin{itemize}
    \item \(\theta = 0\) wThe forward Euler method 
    \[
        M\frac{\vect{u}^{k+1}-\vect{u}^k}{\Delta t} + A\vect{u}^{k} = \vect{f}^k
    \]
    \item \(\theta = 1\) The backward Euler method 
    \[
        M\frac{\vect{u}^{k+1}-\vect{u}^k}{\Delta t} + A\vect{u}^{k+1} = \vect{f}^{k+1}        
    \]
    \item \(\theta = \frac{1}{2}\) The Crank-Nicolson (or trapezoidal) method
    \[
        M\frac{\vect{u}^{k+1}-\vect{u}^k}{\Delta t} + \frac{1}{2}A\left( \vect{u}^{k+1} + \vect{u}^k \right) = \frac{1}{2}\left( \vect{f}^{k+1} \vect{f}^k \right)
    \]
    which is of the second order in \(\Delta t\). 
\end{itemize}
Let us consider the two extremal cases \(\theta = 0\) and \(\theta = 1\). In the first case the system to solve is only the mass matrix \(\frac{M}{\Delta t}\), while in the other case \(\frac{M}{\tstep} + A\). \(M\) is invertible, being positively defined.

In the case \(\theta = 0\) the scheme is not unconditionally stable, and in the case where \(V_h\) is a subspace of finite elements, there is the following stability condition 
\[
    \exists \; c > 0 : \tstep \leq ch^2 \quad \forall \; h > 0
\]
so \(\tstep\) cannot be chosen irrespective of \(h\).

In this case, if we make \(M\) diagonal, we actually decouple the system. This operation is called lumping of the mass matrix.

When \(\theta > 0\), the system will have the from \(K\vect{u}^{k+1} = \vect{g}\), where \(\vect{g}\) is the source term and \(K = \frac{M}{\tstep}\). The latter is invariant in time (the operator \(\loperator\) being independent of time), so, if the spatial mesh doesn't change, it can be factorized only once at the beginning of the process. 

Then, since \(M\) is symmetric, if \(A\) is symmetric, also \(K\) will be symmetric too. Hence, we can use, for example, the Cholesky factorization \(K = HH^T\), with \(H\) being lower triangular. At each timestep, then, will be solved two triangular systems 
\begin{align*}
    H\vect{y} &= \vect{g} \\
    H^T \vect{u}^{k+1} = \vect{y}
\end{align*}
\subsection{A priori estimate}
Let us know consider \eqref{weak_formulation_heat_pbl}. Since the corresponding equation must hold for each \(v \in V\), it will be legitimate to set \(v = u(t)\) with \(t\) being given. yielding 
\begin{equation}
    \int_\Omega \partialderivative{u(t)}{t} u(t) = \frac{1}{2}\partialderivative{\null}{t} \int_\Omega \abs{u(t)}^2 \, d\Omega = \frac{1}{2} \partialderivative{\null}{t} \ltwonorm{u(t)}^2
    \label{a_priori_est_pbl}
\end{equation}
Considering the individual terms, the first one is 
\begin{equation}
    \int_\Omega \partialderivative{u(t)}{t} u(t) \, d\Omega = \onehalf \partialderivative{\null}{t} \int_\Omega \abs{u(t)}^2 \, d\Omega = \onehalf \partialderivative{\null}{t} \ltwonorm{u(t)}^2
    \label{first_term_est_pbl}
\end{equation}
Assuming that the bilinear form is coercive, with \(\alpha\) coercivity constant, we obtain 
\[
    a(u(t), u(t)) \geq \alpha \norm{u(t)}^2_V
\]
while, thanks to the CS inequality we find:
\begin{equation}
    (f(t), u(t)) \leq \ltwonorm{f(t)}\ltwonorm{u(t)}
    \label{CS_inequality_pbl}
\end{equation}
So \eqref{a_priori_est_pbl} becomes 
\[
    \frac{1}{2} \partialderivative{\null}{t} \ltwonorm{u(t)}^2 + \alpha \norm{u(t)}_V^2 \leq \ltwonorm{f(t)}\ltwonorm{u(t)}
\] 
Now let's define two important inequalities 
\begin{definition}[Young's inequality]
    \(\forall \; a, b \in \real\)
    \begin{equation}
        ab \leq \epsilon\alpha^2 + \frac{1}{4\epsilon} b^2 \quad \forall \; \epsilon >0 \label{young_inequality_pbl}
    \end{equation}
\end{definition}
\begin{definition}[Poincaré inequality]
    If \(\Gamma_D\) is a set of positive measure, then:
    \begin{equation}
        \exists \; C_{\Omega} > 0 : \ltwonorm{v} \leq C_\Omega \ltwonorm{\grad v} \quad \forall \; v \in H^1_{\Gamma_D(\Omega)} \label{poincare_inequality_pbl}
    \end{equation}
\end{definition}
By using these two we obtain 
\begin{equation}
    \begin{aligned}
        \frac{1}{2} \partialderivative{\null}{t} \ltwonorm{u(t)}^2 + \alpha \ltwonorm{\grad u}^2 &\leq \ltwonorm{f(t)}\ltwonorm{u(t)} \\
        & \leq \frac{C_\Omega^2}{2\alpha} \ltwonorm{f(t)}^2 + \frac{\alpha}{2} \ltwonorm{\grad u(t)}^2
        \label{a_priori_not_integrated_pbl}
    \end{aligned}
\end{equation}
Then, by integrating in time, we obtain, for all \(t > 0\)
\begin{equation}
    \ltwonorm{u(t)}^2 +\alpha \int_0^t \ltwonorm{\grad u(s)}^2 \, ds \leq \ltwonorm{u_0}^2 + \frac{C_\Omega^2}{\alpha} \int_0^t \ltwonorm{f(s)}^2 \, ds
    \label{energy_estimate_pbl}
\end{equation}
This is an a priori energy estimate. Note that 
\[
    \frac{1}{2} \partialderivative{\null}{t} \ltwonorm{u(t)}^2 = \ltwonorm{u(t)} \partialderivative{\null}{t} \ltwonorm{u(t)} 
\]
then, from \eqref{a_priori_est_pbl}, using \eqref{first_term_est_pbl}, \eqref{CS_inequality_pbl} and \eqref{poincare_inequality_pbl}
\begin{equation}
    \begin{split}
        \ltwonorm{u(t)} \partialderivative{\null}{t} \ltwonorm{u(t)} + \frac{\alpha}{C_\Omega} \ltwonorm{u(t)} \ltwonorm{\grad u(t)} \\
        \leq  \ltwonorm{f(t)}\ltwonorm{u(t)}, \quad t>0
    \end{split}
\end{equation}
If \(\ltwonorm{u(t)} \neq 0\), we can divide by \(\ltwonorm{u(t)}\) and integrate in time to obtain another estimate.
\begin{equation}
    \ltwonorm{u(t)} \leq \ltwonorm{u_0} + \int_0^t \ltwonorm{f(s)} \, ds \quad t >0
    \label{another_a_priori_pbl}
\end{equation}
Let us now use the first inequality in \eqref{a_priori_not_integrated_pbl} and integrate in time to yield 
\begin{equation}
    \begin{aligned}
        \ltwonorm{u(t)}^2 + 2\alpha \int_0^t \ltwonorm{\grad u(s)}^2 \, ds 
        &\underset{\eqref{a_priori_not_integrated_pbl}}{\leq} \ltwonorm{u(t)}^2 + 2\int_0^t \ltwonorm{f(s)}\ltwonorm{u(s)} \, ds \\
        &\underset{\eqref{another_a_priori_pbl}}{\leq} \ltwonorm{u_0}^2 + 2\int_0^t \ltwonorm{f(s)} \cdot \Bigg( \ltwonorm{u_0} \\
        &\qquad + \int_0^s \ltwonorm{f(\tau)} \, d\tau \Bigg) \, ds \\
        &= \ltwonorm{u_0}^2 \int_0^t \ltwonorm{f(s)}\ltwonorm{u_0}\, ds \\
        &\qquad+ 2 \int_0^t \ltwonorm{f(s)}\int_0^s \ltwonorm{f(\tau)} \, d\tau ds
    \end{aligned}
    \label{16_slide_pbl}
\end{equation}
Now, noticing that 
\[
    \ltwonorm{f(s)} \int_0^s \ltwonorm{f(\tau)} \, d\tau = \pderivative{s} \left( \int_0^s \ltwonorm{f} \, d\tau \right)^s
\]
we can rewrite the right hand side of \eqref{16_slide_pbl} as:
\begin{equation*}
    \begin{split}
        \ltwonorm{u_0}^2 \int_0^t \ltwonorm{f(s)}\ltwonorm{u_0}\, ds+ 2 \int_0^t \ltwonorm{f(s)}\int_0^s \ltwonorm{f(\tau)} \, d\tau ds \\
        = \left( \ltwonorm{u_0} +\int_0^t \ltwonorm{f(s)} \, ds \right)^2
    \end{split}
\end{equation*}
Therefore we can obtain the following estimate 
\begin{equation}
    \begin{split}
        \left( \ltwonorm{u(t)}^2 + 2\alpha \int_0^t \ltwonorm{\grad u(s)}^2 \, ds \right)^{\onehalf} \\
        \leq \ltwonorm{u_0}^2 + \int_0^t \ltwonorm{f(s)} \, ds \quad t >0
    \end{split}
    \label{hopefully_last_estimate_pbl}
\end{equation}
Now that we have found an estimate for \eqref{weak_formulation_heat_pbl}, we can now estimate its discretization \eqref{semi-discretization_pbl}, like \eqref{energy_estimate_pbl}
\begin{equation}
    \ltwonorm{u_h(t)}^2 +\alpha \int_0^t \ltwonorm{\grad u_h(s)}^2 \, ds \leq \ltwonorm{u_{0h}}^2 + \frac{C_\Omega^2}{\alpha} \int_0^t \ltwonorm{f(s)}^2 \, ds
    \label{energy_est_galerkin_pbl}
\end{equation}
We can proceed as before, simply taking for every \(t>0\), \(v_h = u_h(t)\). Since \(u_h(0) = u_{0h}\) we obtain the discrete counterparts of \eqref{another_a_priori_pbl} and \eqref{hopefully_last_estimate_pbl} 
\begin{equation}
    \ltwonorm{u_h(t)} \leq \ltwonorm{u_{0h}(t)} + \int_0^t
    \ltwonorm{f(s)} \,ds \quad t > 0
    \label{another_a_priori_disc_pbl}
\end{equation}
and 
\begin{equation}
    \begin{split}
            \left( \ltwonorm{u_h(t)}^2 + 2\alpha \int_0^t \ltwonorm{\grad u_h(s)}^2 \, ds\right)^{\onehalf} \\
            \leq \ltwonorm{u_{0h}(t)} + \int_0^t \ltwonorm{f(s)} \, ds \quad t > 0
    \end{split}
\end{equation}
\subsection{Convergence analysis}
\begin{theorem}
    There exists a constant \(C > 0\) independent of both \(t\) and \(h\) s.t. 
    \begin{equation*}
        \begin{split}
            \left\{ \ltwonorm{u(t) - u_h(t)}^2 + \alpha \int_0^t \ltwonorm{\grad u(s) -\grad u_h(s)}^2 \, ds \right\}^{\onehalf} \\
            \leq Ch^r \left\{ \seminorm{u_0}{H^r(\Omega)}^2 + \int_0^t \seminorm{u(s)}{H^{r+1}( Omega)}^2 \, ds + \int_0^t \seminorm{\partialderivative{u(s)}{s}}{H^{r+1}(\Omega)}^2 \, ds \right\}^{\onehalf}
        \end{split}
    \end{equation*}
\end{theorem}
\subsection{Stability analysis of the \texorpdfstring{\(\theta\)}{theta}-method}
We can now analyze the stability of discretized problem. 
By applying the \(\theta\)-method to the Galerkin problem \eqref{semi-discretization_pbl} we obtain 
\begin{equation}
    \begin{split}
        \left( \frac{u_h^{k+1}-u_h^k}{\tstep}, v_h \right) + a(\theta u_h^{k+1} + (1-\theta) u^k_h, v_h) \\
        = \theta F^{k+1}(v_h) + (1-\theta) F^k(v_h) \quad \forall \; v_h \in V_h
    \end{split}
    \label{theta_method_stab_pbl}
\end{equation}
for each \(k \geq 0\), with \(F^k\) indicating the functional evaluated at the time \(k\).
For the analysis we will consider \(F=0\), and the case of implicit Euler \(\theta = 1\).
\[
    \left( \frac{u_h^{k+1}-u^k_h}{\tstep}, v_h \right) + a(u^{k+1}_h, v_h) = 0 \quad \forall \; v_h \in V_h
\]
By choosing \(v_h = u_h^{k+1}\), we obtain 
\[
    ( u_h^{k+1}, u_h^{k+1} ) +\tstep a(u^{k+1}_h, u_h^{k+1}) = (u_h^{k}, u_h^{k+1})
\]
and then, thanks to these inequalities 
\begin{align*}
    a(u_h^{k+1}, u_h^{k+1}) &\geq \alpha \norm{u_h^{k+1}}_V^2 \\
    (u_h^{k},u_h^{k+1}) &\leq \onehalf \ltwonorm{u_h^{k}}^2 + \onehalf \ltwonorm{u_h^{k+1}}^2
\end{align*}
which are derived from the coercivity of \(a(\cdot, \cdot)\) and the CS inequality we obtain 
\begin{equation}
    \ltwonorm{u_h^{k+1}}^2 +2\alpha \tstep \norm{u_h^{k+1}}_V^2 \leq \ltwonorm{u_h^{k}}^2
    \label{22_slide_pbl}
\end{equation}
Observing that \(\norm{u_h^{k+1}}_V \geq \ltwonorm{u_h^{k+1}}\), we deduce from \eqref{22_slide_pbl} that 
\[
    (1+2\alpha \tstep)\ltwonorm{u_h^{k+1}}^2 \leq \ltwonorm{u_h^{k}}^2
\]
hence 
\[
    \ltwonorm{u_h^{k+1}} \leq \frac{1}{\sqrt{1+2\alpha \tstep}} \ltwonorm{u_h^{k}}
\]
which entails 
\[
    \ltwonorm{u_h^{k}} \leq \left( \frac{1}{\sqrt{1+2\alpha \tstep}} \right)^k\ltwonorm{u_{0h}}
\]
and therefore 
\[
    \lim_{k\to \infty} \ltwonorm{u_h^{k}} = 0
\]
so the backward Euler method is absolutely stable without any restriction on \(\tstep\).

Now we assume \(f \neq 0\) 
\[
    \underbrace{\left( \frac{u_h^{k+1} - u_h^{k}}{\tstep}, u_h^{k+1} \right)}_{(1)} + \underbrace{a(u_h^{k+1},u_h^{k+1})}_{(2)} = \underbrace{\int_\Omega f^{k+1}u_h^{k+1}}_{(3)}
\]
where 
\begin{align*}
    (1) &\geq \frac{1}{2\tstep t} \left( \ltwonorm{u_h^{k+1}}^2 -\ltwonorm{u_h^{k}}^2 \right) \\
    (2) &\geq \alpha \ltwonorm{u_h^{k+1}}^2 \\
    (3) &\underset{\txt{\tiny{(CS)}}}{\leq} \ltwonorm{f^{k+1}} \norm{u_h^{k+1}}_V \underset{\txt{\tiny{(Young)}}}{\leq} \frac{1}{2\alpha} \ltwonorm{f^{k+1}}^2 + \frac{\alpha}{2} \norm{u_h^{k+1}}_V^2
\end{align*}
Then, after summation on \(k\), for \(k = 0,\ldots, n-1\):
\begin{equation*}
    \ltwonorm{u_h^2} + \underbrace{\alpha \sum_{k=1}^{n}\tstep \norm{u_h^{k}}_V^2}_{\simeq \alpha \int_0^{t_n} \norm{u_h(t)}_V^2 \, dt} \leq \ltwonorm{u_{0h}}^2 + \underbrace{\frac{1}{\alpha} \sum_{k=1}^{n} \tstep \ltwonorm{f^k}^2}_{\simeq\frac{1}{\alpha} \int_0^{t_n} \ltwonorm{f^k}^2 \, dt}
\end{equation*}
meaning that we have unconditional stability. 

Now, before analyzing the general case, where \(0 \leq \theta \leq 1\), we need the following definition 
\begin{definition}
    We say that the scalar \(\lambda\) is an eigenvalue of the bilinear form \(a(\cdot, \cdot): V \times V \to \real\) and that \(w \in V\) is its corresponding eigenfunction if 
    \[
        a(w,v) = \lambda(w,v) \quad \forall v \in V    
    \]
\end{definition}
If the bilinear form \(\bilinear\) is symmetric and coercive, it has positive and real eigenvalues forming an infinite sequence, moreover, its eigenfunctions form a basis of the space \(V\). The eigenvalues and eigenfunctions of \(\bilinear\) can be approximated by finding the pairs \(\lambda_h \in \real\) and \(w_h \in V_h\), which satisy 
\begin{equation}
    a(w_h, w_h) \lambda_h (w_h, v_h) \quad \forall \; v_h \in V_h
    \label{eigenvalues_of_bilinear_pbl}
\end{equation}
From an algebraic viewpoint, problem \eqref{eigenvalues_of_bilinear_pbl} can be formulated as 
\[
    A\vect{w} = \lambda_h M \vect{w},
\]
where \(A\) is the stiffness matrix and \(M\) the mass matrix. This is a generalized eigenvalue problem. Such eigenvalue are all positive and \(N_h\) (the usual dimension of \(V_h\)). After ordering them in ascending order we have
\[
    \lambda_h^{N_h} \quad \txt{for } N_h \to \infty.
\]
Moreover, the corresponding eigenfunctions form a basis for the subspace \(V_h\) and can be chosen to be orthonormal w.r.t. the scalar product of \(L^2(\Omega)\). This means that, by denoting with \(w^i_h\) the eigenfunction corresponding to the eigenvalue \(\lambda^i_h\), we have \((w^i_h, w_h^j) = \delta_{ij}\), \(\forall \; i,j = 1,\ldots,N_h\). Thus, each function \(v_h \in V_h\) can be represented as follows 
\[
    v_h(\xvec) = \sum_{j=1}^{N_h} v_j w^j_h(\xvec)
\]
and, thanks to the eigenfunctions orthonormality
\begin{equation}
    \ltwonorm{v_h}^2 = \sum_{j=1}^{N_h} v_j^2
    \label{orthonormality_pbl}
\end{equation}

Let us know consider an arbitrary \(\theta \in [0,1]\) and assume that \(\bilinear\) is symmetric. Since \(u_h^k \in V_h\) we can write 
\[
    u_h^k(\xvec) = \sum_{j=1}^{N_h} u^k_j w^j_h(\xvec)
\]
In this case, however, \(u_j^k\) no longer represents the nodal values of \(u_h^k\).

If we now set \(F=0\) in \eqref{theta_method_stab_pbl} and take \(v_h = w_h^i\), we find 
\[
    \frac{1}{\tstep} \sum_{k=1}^{N_h} [u_j^{k+1} - u_j^k](w_h^i, w_h^j) + \sum_{j=1}^{N_h} + \sum_{j=1}^{N_h}[\theta u_j^{k+1} + (1-\theta)u_j^k]a(w_h^j, w_h^i) = 0,
\]
for each \(i = 1,\ldots, N_h\). For each pair \(i,j = 1, \ldots, N_h\) we have 
\[
    a(w_h^j, w_h^i) = \lambda^j_h (w_h^j, w_h^i) = \lambda^i_h,
\]
and thus, for each \(i = 1,\ldots, N_h\), 
\[
    \frac{u_i^{k+1} - u^k_i}{\tstep} + [\theta u^{k+1}_i + (1-\theta)u^k_i] \lambda_h^i = 0.
\]
Solving for \(u^{k+1}_i\), we find:
\[
    u_i^{k+1} = u_i^k \frac{1-(1-\theta) \lambda_h^i \tstep}{1+\theta \lambda_h^i\tstep}.
\]
Now, recalling \eqref{orthonormality_pbl}, we can conclude that absolute stability comes from the followin inequality
\[
    \abs{\frac{1-(1-\theta) \lambda_h^i \tstep}{1+\theta \lambda_h^i\tstep}} < 1
\]
that is 
\[
    -1-\theta \lambda_h^i \tstep < 1 - (1-\theta) \lambda_h^i \theta < 1+\theta \lambda_h^i \theta.
\]
Hence, 
\[
    -\frac{2}{\lambda_h^i \tstep} -\theta < \theta -1 < \theta.
\]
While the second inequality is always verified, we can rewrite the first one as: 
\[
    2\theta - 1 > -\frac{2}{\lambda_h^i \tstep}. 
\]
If \(\theta \geq \onehalf\), the left hand side is nonnegative, while the right hand side is negative, so the relation always holds. In the case \(\theta < \onehalf\), the inequality is satisfied if 
\begin{equation}
    \tstep < \frac{2}{(1-2\theta) \lambda_h^i}.
    \label{stability_forward_euler_pbl}
\end{equation}
So, we have that 
\begin{itemize}
    \item if \(\theta \geq \onehalf\), the \(\theta\)-method is unconditionally absolutely stable, for every value of \(\tstep\).
    \item if \(\theta < \onehalf\) the \(\theta\)-method is absolutely stable only if \eqref{stability_forward_euler_pbl} is satisfied.
\end{itemize}
Thanks to the definition of eigenvalue \eqref{eigenvalues_of_bilinear_pbl} and the continuity property of \(\bilinear\), we deduce that 
\[
    \lambda_h^{N_h} = \frac{a(w_{N_h}, w_{N_h})}{\ltwonorm{w_{N_h}}^2} \leq \frac{M\norm{w_{N_h}}_V^2}{\ltwonorm{w_{N_h}}^2} \leq M(1+C^2h^{-2}).
\]
The constant \(C > 0\), which appears in the latter step derives from the following inverse inequality 
\[
    \exists \; C > 0 : \ltwonorm{\grad v_h} \leq Ch^{-1} \ltwonorm{v_h} \quad \forall \; v_h \in V_h
\]
Hence, for \(h\) small enough, \(\lambda_h^{N_h} \leq Ch^{-2}\). In fact, we can prove that \(\lambda^{N_h}_h\) is indeed of the order \(h^-2\), that is \
\[
    \lambda_h^{N_h} = \max_i \lambda_h^i \simeq ch^{-2}. 
\]
Knowing that, we obtain the stability of the \(\theta\)-method for \(\theta < \onehalf\), which is 
\begin{equation}
    \tstep \leq C(\theta) h^2
    \label{forward_euler_stab_pbl}
\end{equation}
where \(C(\theta)\) denotes a positive constant depending on \(\theta\). We cannot choose \(\tstep\) without keeping in mind \(h\).

\subsection{Convergence analysis}
\begin{theorem}
    Under the hypothesis that \(u_0, f\) and the exact solution are sufficiently regular, the following a priori estimate holds \(\forall \; n \geq 1\): 
    \[
        \ltwonorm{u(t^n) - u_h^n}^2 + 2\alpha \tstep \sum_{k=1}^{n}\norm{u(t^k) - u^k_n}_V^2 \leq C(u_0, f, u) (\tstep^{p(\theta)} + h^{2r})
    \]
    where \(p(\theta) = 2\) if \(\theta \neq \frac{1}{2}\), \(p(\onehalf) = 4\) and \(C\) depends on its arguments, but not on \(\tstep\) or \(h\).
\end{theorem}
\subsection{Parabolic ADR equation}
Consider the parabolic PDE, where \(\Omega \subset \real^2\) is an open bounded domain
\begin{equation}
    \begin{cases}
       \displaystyle \partialderivative{u}{t} - \mu \Delta u + \beta \cdot \grad u + \sigma u = f & \txt{in }\Omega \times (0,T) \\
       u = 0 & \txt{on }\boundary \times (0,T) \\
       u(0) = u_0 & \txt{in } \Omega
   \end{cases}
   \label{parabolic_adr_pbl}
\end{equation}
where \(\mu , \beta, \sigma\) and \(f\) are regular functions, satisfying: 
\begin{align*}
    & 0 < \mu_0 \leq \mu \leq \mu_1 & \txt{a.e. in } \Omega \\
    \abs{\beta} \leq b_1 & \txt{a.e. in } \Omega \\
    0 < \sigma_0 \leq \sigma \leq \sigma_1 & \txt{a.e. in } \Omega
\end{align*}
Then, introducing a finite element space \(V_h \subset H^1_0(\Omega)\), the semi-discrete Galerkin formulation reads 
\begin{equation}
    \begin{split}
        \txt{for all } t \in (0, T] \txt{ find }u_h(t) \in V_h : \int_\Omega \partialderivative{u_h(t)}{t} v_h \, dx + \int_\Omega \mu \grad u_h (t) \cdot \grad v_h + \int_\Omega \beta \cdot \grad u_h(t) v_h \\
        + \int_\Omega \sigma u_h(t) v_h = \int_\Omega f v_h \quad \forall \; v_h \in V_h 
    \end{split}
    \label{semi_weak_form_parabolic_adr_pbl}
\end{equation}
And such that \(u_h(0) = u_{0h}\), where \(u_{0h}\) is the projection of the initial condition into \(V_h\).
\subsubsection{A semimplicit scheme}
Consider now a time-advancin scheme, where the diffusion and reaction term are treated implicitly, while the advection term is treated explicitedly. Let us denote \(t_k = k\Delta t\), for \(k = 0, \ldots, N\), where \(\tstep = \frac{T}{N}\). Let now \(u_h^{k}\) be the approximation of \(u(t_k)\). A fully discretized version of \eqref{semi_weak_form_parabolic_adr_pbl} reads:
\begin{equation}
    \begin{cases}
        \begin{aligned}
            \left( \dfrac{u_h^{k+1}- u^k_H}{\tstep}, v_h \right) &+ \left( \mu \grad u_h^{k+1}, v_h \right) + \left( \beta \cdot \grad u_h^{k} , v_h \right) \\
            &+ \left( \sigma u_h^{k+1}, v_h \right) = (f,v_h) \quad \forall \; v_h \in V_h, \ k = 0, \ldots, N-1
        \end{aligned} \\
        u_h(0) = u_{0h}
    \end{cases}
    \label{weak_form_parabolic_adr_pbl}
\end{equation}
\begin{theorem}
    If the coefficients of the problem staisfy 
    \begin{equation}
        b_1^2 < 4\mu_0 \sigma_0
        \label{30_slide_pbl}
    \end{equation}
    then the semimplicit scheme \eqref{weak_form_parabolic_adr_pbl} is absolutely stable for any chance of \(\tstep\). Consider now the case \(\sigma = 0\). If the coefficients of the problem satisfy 
    \begin{equation}
        b_1 < \frac{\mu_0}{C_p}
    \end{equation}
    with \(C_p\) being the Poincaré constant, then the scheme is absolutely stable, for any choice of \(\tstep\).
\end{theorem}
\begin{proof}
    Let us choose \(v_h = u_h^{k+1}\). We have 
    \begin{align*}
        & \left( \mu \grad u_h^{k+1}, \grad u_h^{k+1} \right) \geq \mu_0 \ltwonorm{\grad u_h^{k+1}}^2 \\
        & \left( \sigma u_h^{k+1}, u_h^{k+1} \right) \geq \sigma_0 \ltwonorm{u_h^{k+1}}^2
    \end{align*}
    which entails, for every \(k\)
    \begin{equation*}
        \begin{split}
            \ltwonorm{u_h^{k+1}}^2 + \tstep \mu_0 \ltwonorm{\grad u_h^{k+1}}^2 + \tstep \sigma_0 \ltwonorm{u_h^{k+1}}^2 \leq \abs{\left( u_h^{k}, u_h^{k+1} \right)} + \tstep \abs{\left( \beta \cdot \grad u_h^{k}, u_h^{k+1} \right)}
        \end{split}
    \end{equation*}
    The two right-hand side terms can be bounded by combining \eqref{young_inequality_pbl} and \eqref{CS_inequality_pbl}: 
    \begin{align*}
        & \abs{\left( u_h^{k}, u_h^{k+1} \right)} \leq \frac{1}{2 \eta_1} \ltwonorm{u_h^{k}}^2 + \frac{\eta_1}{2} \ltwonorm{u_h^{k+1}}^2 \\
        & \abs{\left( \beta \cdot \grad u_h^{k}, u_h^{k+1} \right)} \leq \frac{b_1}{2\eta_2} \ltwonorm{\grad u_h^{k}}^2 + \frac{\eta_2 b_1}{2} \ltwonorm{u_h^{k+1}}^2
    \end{align*}
    where the positive constant \(\eta_1\) and \(\eta_2\) will be later fixed accordingly. Now we end up with the following inequality
    \begin{equation*}
        \begin{split}
            \underbrace{\left[ 1 + \tstep \sigma_0 - \frac{\eta_1}{2} - \frac{\tstep \eta_2 b_1}{2} \right]}_{A} \ltwonorm{u_h^{k+1}}^2 + \underbrace{\tstep\mu_0}_{B} \ltwonorm{\grad u_h^{k+1}}^2 \\
            \leq \underbrace{\frac{1}{2\eta_1}}_{A'} \ltwonorm{u_h^{k}}^2 + \underbrace{\frac{\tstep b_1}{2 \eta_2}}_{B'} \ltwonorm{\grad u_h^{k}}^2 
        \end{split}
    \end{equation*}
    In order to prove stability we need \(A > A'\) and \(B > B'\). In fact, if this were true, we would end up with 
    \[
        A\ltwonorm{u_h^{k+1}}^2 + B\ltwonorm{\grad u_h^{k+1}}^2 \leq \max\left( \frac{A'}{A}, \frac{B'}{B} \right) \left[ A\ltwonorm{u_h^{k+1}}^2 + B \ltwonorm{u_h^{k+1}}^2 \right],
    \]
    which is the seeked stability in the norm \(\normdot_{A,B}:= \left( A\ltwonorm{\cdot}^2 + B\ltwonorm{\grad \cdot}^2 \right)^\onehalf\), equivalent to the standard \(V_h\) norm.

    Therefore, we look for a suitable choice of \(\eta_1\) and \(\eta_2\) that ensures \(A > A'\) and \(B > B'\). The second inequality is satisfied if and only if 
    \[
        \eta_2 = \frac{b_1 +\epsilon}{2\mu_0} 
    \]
    for some \(\epsilon > 0\).
    

    Hence, the first inequality reads 
    \[
        1 + \tstep \sigma_0 -\frac{\tstep b_1(b_1 + \epsilon)}{4\mu_0} > \frac{1}{2\eta_1} + \frac{\eta_1}{2}
    \]
    The rigth hand side is minimized for \(\eta_1 = 1\), thus leading to the condition 
    \begin{equation}
        4\frac{\mu_0\sigma_0}{b_1(b_1+\epsilon)} > 1
        \label{32_slide_pbl}
    \end{equation}
    Clearly, it is possible to find \(\epsilon > 0\) such that \eqref{32_slide_pbl} holds if and only if
    \begin{equation}
        b_1^2 \leq 4\mu_0\sigma_0
        \label{33_slide_pbl}
    \end{equation}
    In conclusion, whenever the coefficients of the problem satisfy the condition \eqref{33_slide_pbl}, the scheme \eqref{weak_form_parabolic_adr_pbl} is absolutely stable for any choice of \(\tstep\).

    Let us now consider \(\sigma= 0\). Proceeding as before, we have: 
    \begin{equation*}
        \begin{split}
            \left[ 1-\frac{\eta_1}{2} - \frac{\tstep \eta_2 b_1}{2} \right] \ltwonorm{u_h^{k+1}}^2 + \tstep \mu_0 \ltwonorm{\grad u_h^{k+1}}^2 \\ 
            \leq \frac{1}{2\eta_1} \ltwonorm{u_h^{k}}^2 + \frac{\tstep b_1}{2 \eta_2} \ltwonorm{\grad u_h^{k}}^2
        \end{split}
    \end{equation*}
    Introducing now a constant \(\omega \in (0,1)\), we have (thanks to \eqref{poincare_inequality_pbl}):
    \begin{equation*}
        \begin{aligned}
            \ltwonorm{\grad u_h^{k+1}}^2 &= (1-\omega) \ltwonorm{\grad u_h^{k+1}}^2 + \omega \ltwonorm{ \grad u_h^{k+1}}^2 \\
            &\geq \frac{1-\omega}{C_p} \ltwonorm{u_h^{k+1}}^2 + \omega \ltwonorm{\grad u_h^{k+1}}^2
        \end{aligned}
    \end{equation*}
    Combining the latter inequalities, we obtain 
    \begin{equation*}
        \begin{split}
            \underbrace{\left[ 1 - \frac{\eta_1}{2} - \frac{\tstep \eta_2 b_1}{2} - \frac{(1-\omega)\tstep \mu_0}{C_p^2}\right]}_{A} \ltwonorm{u_h^{k+1}}^2 + \underbrace{\omega \tstep \mu_0}_{B} \ltwonorm{\grad u_h^{k+1}}^2 \\
            \leq \underbrace{\frac{1}{2\eta_1}}_{A'} \ltwonorm{u_h^{k}}^2 + \underbrace{\frac{\tstep b_1}{2 \eta_2}}_{B'} \ltwonorm{\grad u_h^{k}}^2 
        \end{split}
    \end{equation*}
    As before, we look for conditions such that \(A >A'\) and \(B>B'\). The second inequality is satisfied if and only if
    \[
        \eta_2 =\frac{b_1 + \epsilon}{2\omega \mu_0}
    \]
    for some \(\epsilon > 0\).
    Then, the first inequality reads
    \[
        1 - \frac{\tstep b_1 (b_1 + \epsilon)}{4\omega \mu_0} + \frac{(1-\omega) \tstep \mu_0}{C^2_p} > \frac{1}{2\eta_1} + \frac{\eta_1}{2}
    \]
    The right hand side is minimized for \(\eta_1 = 1\). Rearranging the term, we get 
    \begin{equation}
        -\omega^2 + \omega -\frac{b_1(b_1 +\epsilon)C_p^2}{4\mu_0^2} > 0
        \label{34_slide_pbl}
    \end{equation}
    Real solutions \(\omega \in (0,1)\) exists whenever the discriminant is positive, that is 
    \[
        b_1(b_1+\epsilon)C_p^2 \leq \mu_0^2
    \]
    The latter condition can be satisfied (by suitable choosing of \(\epsilon\)) if and only if 
    \begin{equation}
        b_1 < \frac{\mu_0}{C_p}
        \label{35_slide_pbl}
    \end{equation}
    In conclusion, if \eqref{35_slide_pbl} is satisfied, the scheme is absolutely stable for any choice of \(\tstep\).
\end{proof}