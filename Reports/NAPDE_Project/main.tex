% A LaTeX template for EXECUTIVE SUMMARY of the MSc Thesis submissions to
% Politecnico di Milano (PoliMi) - School of Industrial and Information Engineering
%
% P. F. Antonietti, S. Bonetti, A. Gruttadauria, G. Mescolini, A. Zingaro
% e-mail: template-tesi-ingind@polimi.it
%
% Last Revision: October 2021
%
% Copyright 2021 Politecnico di Milano, Italy. Inc. All rights reserved.

\documentclass[11pt,a4paper]{article}

%------------------------------------------------------------------------------
%	REQUIRED PACKAGES AND  CONFIGURATIONS
%------------------------------------------------------------------------------
% PACKAGES FOR TITLES
\usepackage{titlesec}
\usepackage{color}

% PACKAGES FOR LANGUAGE AND FONT
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[T1]{fontenc} % Font encoding

% PACKAGES FOR IMAGES

\usepackage{subcaption}
\usepackage{graphicx}
\graphicspath{{Images/}} % Path for images' folder
\usepackage{eso-pic} % For the background picture on the title page
%\usepackage{subfig} % Numbered and caption subfigures using \subfloat
\usepackage{caption} % Coloured captions
\captionsetup[figure]{font=small}
\usepackage{transparent}
\usepackage{wrapfig}


% STANDARD MATH PACKAGES
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{bm}
\usepackage[overload]{empheq}  % For braced-style systems of equations

% PACKAGES FOR TABLES
\usepackage{tabularx}
\usepackage{longtable} % tables that can span several pages
\usepackage{colortbl}

% PACKAGES FOR ALGORITHMS (PSEUDO-CODE)
\usepackage{algorithm}
\usepackage{algorithmic}

% PACKAGES FOR REFERENCES & BIBLIOGRAPHY
\usepackage[colorlinks=true,linkcolor=black,anchorcolor=black,citecolor=black,filecolor=black,menucolor=black,runcolor=black,urlcolor=black]{hyperref} % Adds clickable links at references
\usepackage{cleveref}
\usepackage[square, numbers, sort&compress]{natbib} % Square brackets, citing references with numbers, citations sorted by appearance in the text and compressed
\bibliographystyle{plain} % You may use a different style adapted to your field

% PACKAGES FOR THE APPENDIX
\usepackage{appendix}

% PACKAGES FOR ITEMIZE & ENUMERATES
\usepackage{enumitem}

% OTHER PACKAGES
\usepackage{amsthm,thmtools,xcolor} % Coloured "Theorem"
\usepackage{comment} % Comment part of code
\usepackage{fancyhdr} % Fancy headers and footers
\usepackage{lipsum} % Insert dummy text
\usepackage{tcolorbox} % Create coloured boxes (e.g. the one for the key-words)
\usepackage{stfloats} % Correct position of the tables

%-------------------------------------------------------------------------
%	NEW COMMANDS DEFINED
%-------------------------------------------------------------------------
% EXAMPLES OF NEW COMMANDS -> here you see how to define new commands
\newcommand{\bea}{\begin{eqnarray}} % Shortcut for equation arrays
\newcommand{\eea}{\end{eqnarray}}
\newcommand{\e}[1]{\times 10^{#1}}  % Powers of 10 notation
\newcommand{\mathbbm}[1]{\text{\usefont{U}{bbm}{m}{n}#1}} % From mathbbm.sty
\newcommand{\pdev}[2]{\frac{\partial#1}{\partial#2}}
\newcommand{\tinyline}{\vspace{-0.5em} {\setlength{\baselineskip}{0.8\baselineskip} \textcolor{white}{..........} }\\ }

% NB: you can also override some existing commands with the keyword \renewcommand

%----------------------------------------------------------------------------
%	ADD YOUR PACKAGES (be careful of package interaction)
%----------------------------------------------------------------------------
\usepackage{exscale}
\DeclareMathSizes{10}{11}{10}{10}
% \makeatletter
% \renewcommand\everydisplay{\textstyle\@math@crampedtrue}
% \makeatother
%----------------------------------------------------------------------------
%	ADD YOUR DEFINITIONS AND COMMANDS (be careful of existing commands)
%----------------------------------------------------------------------------


% Do not change Configuration_files/config.tex file unless you really know what you are doing.
% This file ends the configuration procedures (e.g. customizing commands, definition of new commands)
\input{Configuration_files/config}

% Insert here the info that will be displayed into your Title page
% -> title of your work
\renewcommand{\title}{Quantifying total uncertainty in physics-informed neural
networks for solving inverse stochastic
problems}

% -> author name and surname
\renewcommand{\author}{Andrea Bonifacio}
% -> MSc course
\newcommand\norm[1]{\lVert#1\rVert}
\newcommand{\course}{Numerical Analysis for Partial Differential Equations}
% -> advisor name and surname
%\newcommand{\advisor}{Dr. Stefano Pagani}
% IF AND ONLY IF you need to modify the co-supervisors you also have to modify the file Configuration_files/title_page.tex (ONLY where it is marked)
%\newcommand{\firstcoadvisor}{Name Surname} % insert if any otherwise comment
%\newcommand{\secondcoadvisor}{Name Surname} % insert if any otherwise comment
% -> academic year
\newcommand{\YEAR}{2022-2023}

%-------------------------------------------------------------------------
%	BEGIN OF YOUR DOCUMENT
%-------------------------------------------------------------------------
\begin{document}

%-----------------------------------------------------------------------------
% TITLE PAGE
%-----------------------------------------------------------------------------
% Do not change Configuration_files/TitlePage.tex (Modify it IF AND ONLY IF you need to add or delete the Co-advisors)
% This file creates the Title Page of the document
\input{Configuration_files/title_page}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%     THESIS MAIN TEXT     %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%-----------------------------------------------------------------------------
% INTRODUCTION
%-----------------------------------------------------------------------------
\section{Introduction}

This report aims to be a recap on Uncertainty Quantification in Physics Informed Neural Networks (PINNs). The decision to focus on using PINNs to solve stochastic problems comes from the fact that there aren't many articles about in the existing literature. Also because solving problems using Scientific Machine Learning techniques helps in keeping a low computational cost, while losing a negligible amount of accuracy in the solution. Most of the work present here comes from \cite{Zhang_2019}.

The brief introduction about Neural Networks (NNs) and Uncertainty Quantification (UQ) comes from \cite{Abdar_2021}.
\subsection{Neural Networks}
In the last few years NNs became very common in a lot of different fields. The creation of frameworks like TensorFlow and Torch helped the diffusion of these tools, thanks to the many features that they brought, like automatic differentiation. Here I'll describe the simplest possible architecture for a neural network. 

In its most basic configuration, a feed-forward neural network is made up of three layers:
\begin{itemize}
    \item Input layer,
    \item Hidden layer,
    \item Output layer.
\end{itemize}
While the first and last layers are quite self-explanatory (the input layer takes a vector \(\bm{x}\) \(D\)-dimensional as an input and the output layer returns an object compatible with the dimensions of the dataset), the hidden layer is made up of multiple units, called neurons, which are basically vector transformations, to which is applied a nonlinear function. The general idea behind is to minimize the loss between the predictions of the model and the real values of the training dataset, by continuously modifying the neurons. Once a satisfying loss between the prediction and real results is reached, the model is ready to be used. 

One of the main features of NNs is that they work really well as function approximators, so one of the logical step after their introduction was to use them to solve PDEs \cite{Lagaris_1998}, but, at the time, it didn't lead anywhere until recently, when the advent of new tools and machine learning frameworks made possible to work again on solving PDEs using neural networks built up for the task.
\subsection{Uncertainty Quantification}
To describe uncertainty in a model, we must distinguish between the two different kinds. The model itself cannot represent reality as a whole, it will always be built up on assumptions that adds up creating epistemic uncertainty, which must be acknowledged, as it is irreducible. In the real world, data are collected by humans and sensors, which are both prone to errors and noise. This is the second kind of uncertainty, called aleatoric. To sum up, the total uncertainty in a model is made of two components:
\[
    \text{TU} = \text{EU} + \text{AU}.
\]

To deal with epistemic uncertainty, it is possible to use a probability distribution over the model parameters. Given a dataset \(D = \left\{ \bm{x}_i, y_i \right\}^N_{i=1}\) where \(\bm{x}_i \in \mathbb{R}^D\) are the inputs and \(y_i \in \left\{ 1,\ldots, C \right\}\) are the corresponding outputs in \(C\) different classes. The idea is to optimize the parameters \(\omega\) of a function \(y = f^\omega(\bm{x})\). The Bayesian approach defines a model likelihood \(p(y\vert\bm{x}, \omega)\), from which we can obtain the posterior distribution for a given dataset, thanks to Bayes' theorem:
\[
    p(\omega \vert X, Y) = \frac{p(Y\vert X, \omega)p(\omega)}{p(Y\vert X)}.
\]
Now, given a test sample \(\bm{x}^*\), a class label can be predicted as 
\[
    p(y^*\vert \bm{x}^*, X, Y) = \int p(y^*\vert\bm{x}^*, \omega) p(\omega \vert X, Y) \, d\omega.
\]

\section{Problem setup}
The problem can be formulated in the following way
\begin{equation}
    \begin{cases}
        \mathcal{N}_x\left[ u(x;\omega); k(x;\omega) \right], & x \in \mathcal{D}, \omega \in \Omega, \\
        \mathcal{B}_x\left[ u(x;\omega) \right] = 0, & x \in \Gamma,
    \end{cases}
    \label{problem_setup}
\end{equation}
where \(\mathcal{N}_x\) is a differential operator, \(\mathcal{D}\) the domain, \(\Omega\) the random space and \(u(x;\omega)\) the solution. On the boundary \(\Gamma\) we have the boundary conditions imposed by the operator \(\mathcal{B}_x\). \(k(x;\omega)\) represent the random parameter.

There are two possible problems: 
\begin{itemize}
    \item Forward problems: in this case, we know the distribution of \(k(x;\omega)\) everywhere on the domain, and the quantity of interest is \(u(x;\omega)\).
    \item Inverse problems: when the information about \(k(x;\omega)\) is partially known, but there is a lot more information about \(u(x;\omega)\) it is possible to infer the full distribution of \(k\).
\end{itemize}

\section{Methodology}
\subsection{PINNs for deterministic systems}
Here is how to solve differential equations using PINNs. To do so, \eqref{problem_setup} must be rewritten replacing the random inputs with a set of finite parameters, to transform it in a deterministic problem.
\begin{equation}
    \begin{cases}
        \mathcal{N}_x\left[ u; \eta \right], & x \in \mathcal{D}, \\
        \mathcal{B}_x\left[ u \right] = 0, & x \in \Gamma.
    \end{cases}
    \label{problem_setup_det}
\end{equation}
The neural network will be denoted by \(\hat{u}(x;\theta)\), which is the approximation of the solution \(u(x)\) with a specific set of parameters \(\theta\) dependent on the network. In a classical deep learning setting, the network should have one constraint, which is to reproduce the values in the dataset. In a physics informed settings, there is a second constraint, which is that the network should comply with the physical laws imposed by \eqref{problem_setup_det}. 
\begin{figure}[H]
    \centering 
    \includegraphics[width=0.5\textwidth]{Images/PINN_structure.png}
    \captionsetup{justification=centering,margin=1cm}
    \caption{Schematic of a PINN for solving differential equations. Figure from \cite{Zhang_2019}.}
\end{figure}
To do so, a second network is defined 
\begin{equation}
    \hat{f}(x;\theta,\eta) := \mathcal{N}_x\left[ \hat{u}(x;\theta);\eta \right],
    \label{second_network}
\end{equation}
which is computed straightforwardly from \(\hat{u}\). The parameters of the second network are the same of the first one. 
Assuming a dataset with \(N_u\) observations on \(u\) collected at \(\{ x^{(i)}_u \}^{N_u}_{i=1}\) and \(N_c\) the number of collocation point in which \(\hat{f}\) will be evaluated.
\begin{algorithm}[H]
\caption{PINN for solving differential equations}\label{alg:cap}
\textbf{Step 1:} Specify the training set 
\[
    \hat{u}: \{ (x^{(i)}_u, u(x^{(i)}_u))\}^{N_u}_{i=1}, \quad \hat{f} = \{x^{(i)}_f, 0\}^{N_c}_{i=1}.
\]
\textbf{Step 2:} Construct a NN \(\hat{u}(x;\theta)\) with random initialized parameters \(\theta\). \\
\textbf{Step 3:} By using automatic differentiation, construct the residual network \(\hat{f}(x;\theta, \eta)\). \\
\textbf{Step 4:} Specify a loss function that includes both networks 
\begin{equation}
    \label{loss_fn}
    \mathcal{L}(\theta, \eta) = \frac{1}{N_u} \sum_{i=1}^{N_u} [\hat{u}(x^{(i)}_u; \theta) - u(x^{(i)}_u)]^2+ \frac{1}{N_c} \sum_{i=1}^{N_c}\hat{f}(x_f^{(i)};\theta, \eta)^2.
\end{equation}
\textbf{Step 5:} Train the networks to find the best parameters by minimizing the loss function:
\[
    \theta = \arg \min \mathcal{L}(\theta,\eta)
\]
\end{algorithm}
\subsection{Moving to a stochastic setting}
The idea now is to analyze a stochastic problem, which brings back \eqref{problem_setup}. A new dataset is needed to collect all the random events. This dataset will be made up of \(N_k\) measurement at \(x^{(i)}_k\) locations in the domain. Given \(N\) measurements, the random instance at the \(s^{\text{\tiny th}}\) event will be called \(\omega_s\). Now, defining \(k_s^{(i)} = k(x_k^{(i)}; \omega_s)\) and \(u_s^{(i)} = u(x_u^{(i)};\omega_s)\), the new dataset is built up like this:
\[
    \mathcal{S}_t = \{\{(x^{(i)}_k, k^{(i)}_s)\}^{N_k}_{i=1},\{(x^{(i)}_u, u^{(i)}_s)\}^{N_u}_{i=1},\{(x^{(i)}_f,0)\}^{N_f}_{i=1}\}^{N}_{s=1}.
\]    
The next step is the arbitrary polynomial chaos (aPC) expansion, which will require:
\begin{enumerate}
    \item Dimension reduction;
    \item Constructing the aPC basis;
    \item Building the NN-aPC network as a surrogate model and train the network for each mode.
\end{enumerate}
\subsubsection{Dimension reduction with PCA}
To find a lower dimensional space, the proposed technique is principal component analysis (PCA), which finds a smaller number of modes able to explain almost all the dataset with enough accuracy. In this case, the reduced dataset will be the one about \(k\).
Let \(K\) be the \(N_k\times N_k\) covariance matrix of the measurements on \(k\)
\[
   K_{i,j} = \text{Cov}(k^{(i)}, k^{(j)}).
\]
Given \(\lambda_l\) and \(\phi_l\) be the \(l\)-largest eigenvalue and its eigenvector, it is possible to write 
\[
    K = \bm{\Phi}^T\bm{\Lambda}\bm{\Phi},
\]
where \(\bm{\Phi} = \phi_1, \phi_2 \ldots, \phi_{N_k}\) is an orthonormal matrix and \(\bm{\Lambda} = \text{diag}(\lambda_1, \lambda_2, \ldots, \lambda_{N_k})\) is a diagonal matrix. Let \(\bm{k}_s = [k^{(1)}_s, k^{(2)}_s \ldots, k^{(N_k)}_s]^T\) be the results of the \(k\) measurement at the \(s^{\text{\tiny th}}\) moment. It is possible then to write
\[
    \bm{\xi}_s = \bm{\Phi}^T \sqrt{\bm{\Lambda}}^{-1} \bm{k}_s,
\]
which is an uncorrelated random vector. Thanks to that, and the fact that \(\bm{k}_0 = \mathbb{E}[\bm{k}]\) is the mean of each measurement, is it possible to rewrite 
\[
    \bm{k}_s \approx \bm{k}_0 + \sqrt{\bm{\Lambda}^M}\bm{\Phi}^M\bm{\xi}^M_s, \quad M < N_k.
\]
The choice of \(M\) depends on the accuracy that one wants to maintain in the low dimensional space.
\subsubsection{Arbitrary polynomial chaos expansion}
Assuming a set of \(M\)-dimensional samples of random vectors 
\[
    S:= \{\bm{\xi}_s\}_{s=1}^N
\]
with hidden probability measure \(\rho(\bm{\xi})\). With a sufficiently large number of observation, it is possible to approximate this probability measure with a discrete one
\[
    \rho(\bm{\xi}) \approx \nu_S(\bm{\xi}) = \frac{1}{N} \sum_{\bm{\xi}_s \in S} \delta_{\bm{\xi}_s}(\bm{\xi}), 
\]
where \(\delta_{\bm{\xi}_s}\) is the Dirac measure. Then a set of \(P+1\) multivariate orthonormal polynomial basis \(\{\psi_\alpha(\bm{\xi})\}^P_{\alpha=0}\) can be constructed using Gram-Schmidt algorithm. 

\subsubsection{Learning stochastic modes}

Now the networks must be trained to predict the stochastic modes of the QoI. The focus will be on the inverse problem, where both \(u\) and \(k\) are partially unknown. The first network \(\hat{u_\alpha}\) takes the spatial coordinates \(x\) as input and returns a \((P+1) \times 1\) vector of the aPC modes of \(u\) evaluated in \(x\), while the \(\hat{k}\) network takes \(x\) as input and outputs a \((M+1) \times 1\) vector of the \(k\) modes. Thanks to that, \(u\) and \(k\) can be approximated as 
\begin{align*}
    \tilde{k}(x; \omega_s) &= \hat{k}_0(x) + \sum_{i=1}^{M} \sqrt{\lambda_i} \hat{k}_i(x) \xi_{s,i}, \\
    \tilde{u}(x;\omega_s) &= \sum_{\alpha=0}^{P} \hat{u_\alpha}(x)\psi_\alpha(\bm{\xi}_s).
\end{align*}
The residual network is then obtained through automatic differentiation. Thanks to the aPC, it is possible to build a network that avoid being an uninterpretable black box. The idea is to build smaller networks which learns the various modes of \(\hat{k}\) and \(\hat{u}\). One network will learn the mean, one the first order basis and so on.
\begin{figure}[H]
    \centering 
    \includegraphics[width=0.5\textwidth]{Images/PINN_structure_3.png}
    \captionsetup{justification=centering,margin=1cm}
    \caption{Schematic of the various networks needed for learning the stochastic modes. There are two smaller networks which calculates the two means and the bigger networks calculate the rest of the modes. Figure from \cite{Zhang_2019}.}
\end{figure}
The loss function is defined as the sum of the squared errors
\[
    \mathcal{L}(\mathcal{S}_t) = MSE_u + MSE_k + MSE_f,
\]
where 
\begin{align*}
    MSE_u &= \frac{1}{NN_u} \sum_{s=1}^{N}\sum_{i=1}^{N_u} \left[ (\tilde{u}(x^{(i)}_u;\omega_s) - u(x^{(i)}_u; \omega_s))^2 \right], \\
    MSE_k &= \frac{1}{NN_k} \sum_{s=1}^{N}\sum_{i=1}^{N_k} \left[ (\tilde{k}(x^{(i)}_k;\omega_s) - k(x^{(i)}_k; \omega_s))^2 \right], \\
    MSE_f &= \frac{1}{NN_f} \sum_{s=1}^{N}\sum_{i=1}^{N_f} \left[ \left(\mathcal{N}_x[\tilde{u}(x^{(i)}_f;\omega_s);\tilde{k}(x^{(i)}_f;\omega_s)]\right)^2 \right].
\end{align*}

\subsubsection{Dropout}

The main problem with standard NNs is that they are not able to quantify model uncertainty. One common way to overcome this problem is the use of dropout. In the deep learning world, dropout is a technique used during the training of neural networks in which some neurons are randomly shut off during the training phase. This is made to prevent excessive co-tuning and to help the information spread across the network. In a classical setting, neurons are shut off only during the training phase, while for uncertainty quantification, they are shut off also at the test phase. Then the prediction \(y\) of the neural network can be estimated with the Monte Carlo (MC) method. Given \(T\) runs 
\[
    \mathbb{E}(y) \approx \frac{1}{T} \sum_{t=1}^{T}\mathcal{NN}_t(x),
\]
where \(\mathcal{NN}_t\) is the \(t^{\text{th}}\) run with some dropped neurons.

\begin{figure}[H]
    \centering 
    \includegraphics[width=0.5\textwidth]{Images/Dropout_example.png}
    \captionsetup{justification=centering,margin=1cm}
    \caption{An example of using dropout for quantify uncertainty. Here the function \(y = x^3e^{-x}\) is approximated using a NN. Mean and standard deviation are calculated from \(1000\) MC runs. Figure from \cite{Zhang_2019}.}
\end{figure}
%-----------------------------------------------------------------------------
% NUMERICAL RESULTS
%-----------------------------------------------------------------------------
\section{Numerical Results}

\subsection{Solving SPDEs}

The problem given involves a stochastic elliptic equation that reads
\begin{equation}
    \begin{cases}
        \displaystyle -\frac{d}{dx} \left( k(x;w)\frac{d}{dx}u \right) = f(x) & x \in [-1,1], \omega \in \Omega \\
        u(-1) = u(1) = 0
    \end{cases}
    \label{inverse_pbl}
\end{equation}
In this case, there are some extra information about \(u(x;\omega)\), but the distribution of the diffusion coefficient \(k(x;\omega)\) is unknown. The forcing term \(f(x) = 10\), while the randomness comes from \(k(x;\omega)\). \(k\) it is modeled and sampled from a non-Gaussian random process such that 
\[
    \log(k(x;\omega)) \sim \mathcal{GP}(k_0(x), \text{Cov}(x, x')),
\]
where the mean \(k_0(x) = \sin({3\pi x}/2)/5\) and the covariance matrix has the form 
\[
    \text{Cov}(x, x') = \sigma^2 \exp\left( - \frac{(x-x')^2}{l_c^2} \right),
\]
where \(\sigma = 0.1\) and \(l_c= 1.0\).

The dataset is built up using the MC sampling method. From a number \(N = 1000\) of trajectories the data at the training points are extrapolated, for both \(u, k\) and \(f\). Same for \(N=500\) trajectories that make up the test set. For the PCA, 6 variables are used, which are enough to explain \(99\%\) of the dataset, while for the aPC, a first order expansion is used.
\begin{figure}[H]
    \centering 
    \includegraphics[width=0.7\textwidth]{Images/L2Error_inv_pbl.png}
    \captionsetup{justification=centering,margin=1cm}
    \caption{Comparing the prediction accuracy against various combinations of networks and values of the L2 regularizer \(\lambda\) (left side). Comparing the prediction accuracy against the number of training points (sensors) for \(u\) and \(k\). Figure from \cite{Zhang_2019}.}
    \label{fig:regularization}
\end{figure}
Two groups of NNs are used, \(\hat{k}_i\) and \(\hat{u_\alpha}\), to calculate the modes of \(k\) and \(u\). After some trial, as seen in Figure \ref{fig:regularization} with various shapes of networks, the optimal shape looks like to be \(4\) hidden layers with \(32\) neurons per layer, with a regularization parameter \(\lambda=0.0005\). Then, looking for the correct amount of training points, the balance is reached in \(7\) training points of \(u\) and \(4\) training points of \(k\).
\begin{figure}[H]
    \centering 
    \includegraphics[width=0.7\textwidth]{Images/Table_L2_Error.png}
    \captionsetup{justification=centering,margin=1cm}
    \caption{Comparing the L2 error when using \(1^{st}\) and \(2^{nd}\) order expansion aPC. Figure from \cite{Zhang_2019}.}
    \label{fig:table}
\end{figure}
As seen in Figure \ref{fig:table}, the \(2^{nd}\) order expansion aPC vastly improves the accuracy of the prediction. In fact, when testing both the \(1^{st}\) and \(2^{nd}\) order expansion is it possible to see how much better the \(2^{nd}\) order expansion performs the task. 
\begin{figure}[H]
    \centering 
    \includegraphics[width=0.7\textwidth]{Images/Mean_STD_2ndorder.png}
    \captionsetup{justification=centering,margin=1cm}
    \caption{Predicted mean and standard deviation of \(u\) for various order expansions. Figure from \cite{Zhang_2019}.}
    \label{fig:mean_u}
\end{figure}
\begin{figure}[H]
    \centering 
    \includegraphics[width=0.7\textwidth]{Images/Mean_STD_k.png}
    \captionsetup{justification=centering,margin=1cm}
    \caption{Predicted mean and standard deviation of \(k\) for various order expansion. Figure from \cite{Zhang_2019}.}
    \label{fig:mean_k}
\end{figure}
Figure \ref{fig:mean_u} shows how the networks performs in predicting the mean and standard deviation of \(u\), in which is already clear that the higher order expansion is more accurate. In Figure \ref{fig:mean_k} is shown that, despite having all the training points where the mean is \(1.0\) and the standard deviation is \(0.1\), the network is able to reconstruct the wavy structure of both, which is way more information that the data would provide.

\subsection{Solving deterministic differential equations with PINNs and dropout}

Is it possible, given a deterministic inverse problem like 
\begin{equation}
    \begin{cases}
        \displaystyle -\frac{d}{dx} \left(e^{\frac{\sin(3\pi x/2)}{5}} \frac{d}{dx}u\right) = f(x), & x \in [-1,1], \\
        u(-1) = u(1) = 0.
    \end{cases}
    \label{pbl:deterministic}
\end{equation}
This time \(f(x) = 9\pi^2\sin(3\pi x /2)/4\) is the forcing term and \(k(x) = \exp(\sin(3\pi x/2)/5)\). For the training points, \(7\) \(u\) and \(5\) \(k\) measurements are set inside the domain. Two separate NNs are built: 
\begin{itemize}
    \item a small scale net with \(2\) hidden layers and \(4\) neurons per layer to model \(u(x)\);
    \item a larger one with \(6\) hidden layers and \(100\) neurons per layer to model \(k(x)\).
\end{itemize} 
Both the network have a dropout rate fixed at \(0.01\).

\begin{figure}[H]
    \centering 
    \includegraphics[width=0.3\textwidth]{Images/dropout_k.png}
    \captionsetup{justification=centering,margin=1cm}
    \caption{Prediction of \(k(x)\) with and without dropout. Figure from \cite{Zhang_2019}.}
    \label{fig:drop_k}
\end{figure}

As seen in Figure \ref{fig:drop_k}, thanks to the use of dropout, the network is able to predict correctly \(k(x)\). The dotted lines, which represent prediction without dropout, are prone to overfit the solution around the data available.
\subsubsection{Active learning for inverse stochastic problems}
Thanks to the uncertainty introduced by the dropout method, it is possible to build an active learning environment. The problem is the same \eqref{pbl:deterministic}. The idea behind this method is to evaluate the dropout network for \(10000\) times to estimate mean and standard deviation. Next, place a new training point where the standard deviation reaches its maximum, unless there is already a training point in a radius \(\rho = 0.003\). In that case, count the already existing training point twice. 

\begin{figure}[H]
    \centering 
    \includegraphics[width=0.6\textwidth]{Images/active_learn.png}
    \captionsetup{justification=centering,margin=1cm}
    \caption{Prediction of \(k\) at the first step (left) and at the step \(15\) (right). Figure from \cite{Zhang_2019}.}
    \label{fig:act_k}
\end{figure}
As seen in Figure \ref{fig:act_k}, letting this process run for \(15\) steps, vastly improves the accuracy of the predictions on \(k(x)\), this is because there are more training points and those are set where the curvature of \(k(x)\) increases, helping the network predict it correctly. 

This active learning method can be used also on stochastic inverse problem, such as \eqref{problem_setup}. The setup is similar to the one used before, where additional training points of \(k\) are placed after \(10000\) iterations where the maximum of the standard deviation of the first mode is reached. The first mode is the one that explain most of the standard deviation, so it makes sense to focus on it.  

\begin{figure}[H]
    \centering 
    \includegraphics[width=0.3\textwidth]{Images/act_lear_2.png}
    \captionsetup{justification=centering,margin=1cm}
    \caption{Error reduction in \(15\) steps. Figure from \cite{Zhang_2019}.}
    \label{fig:act2_k}
\end{figure}
Figure \ref{fig:act2_k} shows well how much the \(L2\) error decreases when more \(k\) sensor are strategically placed following that algorithm. The dropout method is applied only to the network that predicts \(k(x)\) since \(u(x)\) is less impacted by overfitting issues, as seen in Figure \ref{fig:act3_k} and the main goal of an inverse problem is to identify \(k(x)\).
\begin{figure}[H]
    \centering 
    \includegraphics[width=0.6\textwidth]{Images/act_lear23.png}
    \captionsetup{justification=centering,margin=1cm}
    \caption{Predictions of \(k\) (left) and \(u\) (right) at some steps, along with the new training points. Figure from \cite{Zhang_2019}.}
    \label{fig:act3_k}
\end{figure}




%-----------------------------------------------------------------------------
% CONCLUSION
%-----------------------------------------------------------------------------
\section{Conclusions}

According to the authors of the paper, there is little literature about solving stochastic differential equations using PINNs. The method used to quantify uncertainty by employing aPC expansion to represent the stochastic solution is a new kind of approach. The original paper also solves forward problems, which are not present here, since they are solved with the same methodology as inverse problem, but are less challenging. In the paper the aim was to quantify both parametric uncertainty given by the stochastic nature of the problem and approximation uncertainty given by the aPC-PINN solution used to solve the problem. The latter represents how well the PINN is trained, and is modeled by the dropout strategy implemented. This method is capable of solving stochastic inverse problems, in which there are partial information about the solution and the parameters and differs from a classical inverse problem in which the solution is known. Here the data driven method let the model train and then the model is able to predict new information at a very low computational cost.This report is focused on this approach because its novelty made it stand out between the other methods, which were more ``classical'' and with an extensive literature to support them.




%---------------------------------------------------------------------------
%  BIBLIOGRAPHY
%---------------------------------------------------------------------------
% Remember to insert here only the essential bibliography of your work
\bibliography{bibliography.bib} % automatically inserted and ordered with this command

\end{document}