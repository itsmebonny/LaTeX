
Numerical simulations play a critical role in a wide array of scientific and engineering applications, providing insights into the behavior of physical systems under various conditions. Among the most prominent techniques for performing such simulations is Finite Element Modeling (FEM). FEM discretizes a continuous domain into a mesh of finite elements, allowing for the approximation of solutions to complex Partial Differential Equations (PDEs). However, a significant drawback of FEM is its computational intensity, especially when high resolution is required for accurate results. This research aims to explore the potential of Deep Learning (DL) techniques to accelerate FEM simulations, focusing specifically on the deformation of objects subjected to external forces.

The deformation of an object under an applied force is directly tied to its discretization. In FEM, the object is represented by a mesh, where its resolution impacts the accuracy and computational cost of the simulation. High-resolution meshes can capture fine details of deformation, leading to more accurate simulations, but at the cost of increased computational time.

The main goal of this work is to study the efficacy of a reduced order model based on linear modes, enhanced by deep learning techniques, to obtain a realistic simulation of an object in a fraction of the time that would be required by a traditional FEM simulation. The idea is to train a DL model to correct the linear modes, allowing for accurate and fast simulations even with coarse discretizations.

The use of DL techniques to solve scientific problems is not new. Thanks to the rise of new frameworks and libraries, such as TensorFlow \cite{tensorflow2015-whitepaper} and PyTorch \cite{paszke2019pytorchimperativestylehighperformance}, it is now possible to train very complex models on large datasets in a reasonable amount of time \cite{tensorflow2015-whitepaper, pytorch}. For the problem at hand, many different approaches can be found in the existing literature. A common approach is to have the deep learning model predict the whole dynamic of the system, for example MeshGraphNet \cite{pfaffLearningMeshBasedSimulation2021a} or its multiscale version \cite{fortunatoMultiScaleMeshGraphNets2022}. Other approaches can be seen in \cite{jiangMeshfreeFlowNetPhysicsConstrainedDeep2020, hanPredictingPhysicsMeshreduced2022a}. 

\section*{Related Work}

MeshGraphNet \cite{pfaffLearningMeshBasedSimulation2021a} represents a significant advancement in learning mesh-based simulations using graph neural networks. This framework leverages message passing on mesh graphs and can adapt mesh discretization during forward simulation. It has demonstrated accurate prediction of dynamics across various physical systems including aerodynamics, structural mechanics, and cloth, while running faster than traditional simulations. However, one limitation emerges when scaling to high-resolution simulations, as the message passing architecture becomes inefficient when equally distant points in space become further apart in graph space. Another significant limitation is error accumulation during rollout, where small prediction errors compound over time, eventually steering the simulation away from the ground truth as the number of timesteps increases.

To address this limitation, Fortunato et al. \cite{fortunatoMultiScaleMeshGraphNets2022} proposed MultiScale MeshGraphNets, which takes two complementary approaches. First, they showed that accurate surrogate dynamics of high-resolution systems can be learned on much coarser meshes, effectively removing the message passing bottleneck. Second, they introduced a hierarchical approach that passes messages on two different resolutions (fine and coarse), significantly improving accuracy while requiring fewer computational resources. This multiscale approach is particularly relevant to our work as it demonstrates the feasibility of transferring information between different resolution representations. Again, also in this case it is not feasible to use for longer time simulations, as the error will accumulate over time.

Taking a different approach, Jiang et al. \cite{jiangMeshfreeFlowNetPhysicsConstrainedDeep2020} developed MeshfreeFlowNet, a super-resolution framework that generates continuous spatio-temporal solutions from low-resolution inputs. Unlike mesh-based methods, this approach allows outputs to be sampled at any spatio-temporal resolution, making it particularly flexible. MeshfreeFlowNet also incorporates PDE constraints directly into the learning process and uses a fully convolutional encoder that enables training on fixed-size inputs while generalizing to arbitrarily sized domains. When applied to turbulent flows in Rayleigh-Benard convection problems, MeshfreeFlowNet demonstrated significant performance improvements over existing baselines and achieved remarkable computational efficiency, with 96.80\% scaling efficiency across large GPU clusters.

Addressing the error accumulation challenge from a temporal perspective, Han et al. \cite{hanPredictingPhysicsMeshreduced2022a} proposed a novel approach using transformer-style temporal attention mechanisms. Their method captures long-term dependencies through an encoder-decoder structure that creates compact mesh representations of system states, allowing the temporal model to operate efficiently on low-dimensional representations. This architecture significantly outperforms traditional GNN baselines on complex fluid dynamics prediction tasks, from sonic shocks to vascular flow. A key advantage of this approach is its stability during long rollouts without requiring training noise, demonstrating phase-stable predictions even for extended sequences. This represents an important advancement in applying attention-based sequence models to high-dimensional physics simulations.

While all these methods require training on a large dataset of high-resolution simulations, there are other approaches that aim to reduce the amount of data needed for training, by taking advantage of the differentiable nature of deep learning models. These methods are often referred to as physics-informed, because they incorporate physical laws into the learning process. Physics-informed neural networks (PINNs) \cite{raissi2024physicsinformedneuralnetworksextensions} are a prominent example of this approach, where the neural network is trained to satisfy the governing equations of the system being modeled, replacing a classical numerical solver. 

Djeumou et al. \cite{djeumouNeuralNetworksPhysicsInformed2022} developed a framework that effectively incorporates physics-based knowledge into deep neural networks modeling dynamical systems. Their approach uses physical constraints to inform the structure of the neural network and to place constraints on the outputs and internal states of the model. By representing the system's vector field as a composition of known and unknown functions — where the unknown functions are parameterized by neural networks — they demonstrate prediction accuracy improvements of up to two orders of magnitude compared to baseline approaches that don't incorporate prior knowledge.

While traditional PINNs face challenges with scalability and boundary enforcement, Gao et al. \cite{gaoPhysicsinformedGraphNeural2022} introduced a discrete PINN framework based on Graph Convolutional Networks (GCNs) that addresses these limitations. Their approach leverages the variational structure of PDEs to solve both forward and inverse problems in a unified manner. By using piecewise polynomial basis functions, they reduce the search space dimension, which facilitates training and convergence. A key advantage of their method is the ability to strictly impose boundary conditions without tuning penalty parameters, while also effectively handling irregular geometries with unstructured meshes — a significant improvement over CNN-based approaches that struggle with such geometries.

A very recent advancement in Physics-Informed Neural Networks comes from Tierz et al. \cite{Tierz_Alfaro_González_Chinesta_Cueto_2025}, who introduced Thermodynamics-Informed Neural Networks with local inductive biases. Their approach enforces the first and second principles of thermodynamics directly in the network structure, resulting in accuracy improvements of one to two orders of magnitude compared to uninformed networks. While previous thermodynamics-informed approaches required assembling complex global matrices, Tierz's work develops a more efficient local formulation that preserves the node-by-node structure. This innovation demonstrates significant computational efficiency and strong generalization capabilities, allowing accurate predictions even for scenarios substantially different from those in the training data. Their work applies to both solid and fluid mechanics problems, making it particularly relevant to deformation modeling.

Another interesting and recent proposal is given by \cite{Wang_Du_Coros_Thomaszewski_2024}, where the authors extend the concept of linear modes and modal dynamics \cite{Pentland_Williams_1989} to be able to handle larger deformations. The key idea is to obtain a linear approximation of the deformation, then train a network to minimize the energy of the system, so that for every modal coordinate, the network will learn a non-linear correction, effectively learning a series of non-linear modes. This allows for faster simulations by exploiting subspace dynamics, where the simulation is performed in a reduced space to ease computational costs. The authors show that the neural mode method is able to correct some classical problems of the linear modes approach, such as the inability to capture large deformations and producing non-realistic results. 

The present work builds directly upon this last approach, extending it specifically to Neo-Hookean materials, which are widely used in simulating organic tissues and exhibit slightly different non-linear behaviors. A significant advantage of this approach lies in its interpretability, a desired characteristic often lacking in deep learning solutions. Since the method essentially modifies linear modes in a physically meaningful way, the predictions of the network and the combinations of modes can be directly visualized and understood. This transparency allows us to not only obtain accelerated simulations but also gain insight into how the model arrives at its predictions, providing confidence in the results and facilitating further refinement of the approach. 