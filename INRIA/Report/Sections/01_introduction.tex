

\section{Introduction}
Numerical simulations are fundamental to understand complex physical phenomena across diverse scientific and engineering domains. They allow us to explore system behavior under conditions that may be difficult, expensive, or impossible to replicate experimentally. Finite Element Method (FEM) \cite{Quarteroni_2017}stands out as one of the most widely adopted computational techniques for solving complex Partial Differential Equations (PDEs) by discretizing continuous domains into manageable finite element meshes. Despite its proven effectiveness, FEM comes with a significant computational burden, particularly when high-resolution accuracy is essential for reliable results. This thesis investigates how Deep Learning (DL) can be leveraged to dramatically reduce FEM computational costs while maintaining simulation accuracy, with specific focus on modeling object deformation under external forces.


The relationship between degrees of freedom and simulation quality is central to the FEM accuracy/balance trade-off. Full-order FEM models typically require many degrees of freedom (DOFs) to accurately represent complex geometries and physical phenomena; in some applications, thousands or even millions of DOFs are necessary to achieve accurate results. This high dimensionality translates directly into increased computational cost, both in terms of memory requirements and processing time. Reduced-order models (ROMs) \cite{ROM_Quarteroni} offer an alternative by projecting the full-order problem onto a lower-dimensional subspace, thereby significantly reducing the number of DOFs. At least in the context of computational mechanics and when studying small deformations, a ROM such as linear modes \cite{Pentland_Williams_1989} can achieve a level of accuracy sufficiently similar to a full-order model, but with a fraction of the computational cost \cite{Fulton_Modi_Duvenaud_Levin_Jacobson_2019}, \cite{Duenser_Thomaszewski_Poranne_Coros_2022}.
%
In the surgical field, for example, the ability to simulate soft tissue deformation in real-time is crucial for computer-assisted interventions \cite{petit:hal-01930366}. Surgeons must rely on accurate models to predict how tissues will respond to surgical tools, which can vary significantly based on the material properties and the nature of the forces applied. Traditional FEM approaches, while accurate, often struggle with the computational demands of real-time applications, especially in scenarios involving large deformations or complex geometries. The need for faster simulations without sacrificing accuracy has led to the exploration of surrogates to replace or augment traditional FEM methods. 
Rather than replacing traditional FEM entirely, our research aims at developing a reduced-order modeling approach that combines linear modal analysis with deep learning corrections. This approach is particularly suited for nonlinear problems where simple linear projections may not generate accurate approximations. This is achieved by applying a correction to the error introduced in the linear projection of the solution onto the reduced subspace by comparing the energy produced by the linear projection against the ground truth. Since the energy computation is done by using the nonlinear elastic model, this allows the reduced order model to learn the physics of the object, while correcting the errors that are generated during the dimensionality reduction. Various strategies for improving reduced-order models have been proposed in recent literature. Among them, the ROMES method \cite{Drohmann_Carlberg_2015} introduces a statistical framework for modeling and quantifying the error of reduced-order models using Gaussian process regression. This approach has been extended to model the full error in the system state via statistical closure techniques \cite{Pagani_Manzoni_Carlberg_2019}, enabling more robust uncertainty quantification. 

The integration of deep learning into scientific computing has gained a lot of popularity, facilitated by frameworks like TensorFlow \cite{tensorflow2015-whitepaper} and PyTorch \cite{paszke2019pytorchimperativestylehighperformance} and the quick evolution of Graphics Processing Units (GPUs), that in the last decade saw an exponential improvement and helped in solving problem deemed impossible before. Various approaches have emerged in the literature, from end-to-end neural surrogates like MeshGraphNet \cite{pfaffLearningMeshBasedSimulation2021a} and its multiscale variants \cite{fortunatoMultiScaleMeshGraphNets2022}, to physics-constrained approaches exemplified by MeshfreeFlowNet \cite{jiangMeshfreeFlowNetPhysicsConstrainedDeep2020} and mesh-reduced prediction methods \cite{hanPredictingPhysicsMeshreduced2022a}.


This thesis is organized as follows: Section \ref{sec:problem_setting} establishes our mathematical foundation, introducing the Neo-Hookean hyperelastic model for large deformation analysis and reviewing linear modal analysis as a classical dimensionality reduction technique, while acknowledging its limitations for nonlinear systems. Section \ref{sec:methods} presents our core investigation, the ``Neural Modes'' architecture, explaining how neural networks learn nonlinear corrections to linear modes through physics-informed loss functions and how these enhanced modes integrate into dynamic simulations. Finally, Section \ref{sec:numerical_results} validates our approach through comprehensive numerical experiments on 3D benchmark problems.

\section*{State of the Art}

We first examine existing approaches to simulation of object deformation based on neural networks, highlighting both achievements and limitations that motivate our work.

Graph neural networks have emerged as a natural choice for mesh-based simulations. MeshGraphNet \cite{pfaffLearningMeshBasedSimulation2021a} pioneered this direction by treating mesh elements as graph nodes and using message passing to predict dynamics across aerodynamics, structural mechanics, and cloth simulation problems. While achieving impressive speedups over traditional solvers, MeshGraphNet faces scalability challenges: as mesh resolution increases, spatially nearby points become increasingly distant in graph space, reducing message passing efficiency. Additionally, prediction errors accumulate during long-horizon rollouts, eventually causing simulations to diverge from physical reality.

Recognizing these limitations, Fortunato et al. \cite{fortunatoMultiScaleMeshGraphNets2022} developed MultiScale MeshGraphNets, demonstrating that accurate high-resolution dynamics can be learned on coarser meshes while introducing hierarchical message passing across multiple resolutions. This work validates the feasibility of cross-resolution information transfer, though error accumulation remains problematic for extended simulations.

Alternative architectures have explored different trade-offs. MeshfreeFlowNet \cite{jiangMeshfreeFlowNetPhysicsConstrainedDeep2020} abandons mesh constraints entirely, generating continuous spatio-temporal solutions that can be sampled at arbitrary resolutions. By incorporating PDE constraints directly into training and using fully convolutional encoders, this approach achieves remarkable computational efficiency across large GPU clusters, while maintaining flexibility for variable domain sizes, but, as with other CFD-inspired methods, it is primarily designed for fixed meshes and Eulerian frameworks.

Temporal modeling presents another crucial challenge. Han et al. \cite{hanPredictingPhysicsMeshreduced2022a} addressed long-term stability through transformer-style attention mechanisms, creating compact mesh representations that enable efficient temporal modeling. Their encoder-decoder architecture demonstrates phase-stable predictions over extended sequences without requiring training noise, representing a significant advance in applying sequence models to high-dimensional physics problems.

The approaches discussed above typically require extensive datasets of high-resolution simulations for training. Physics-informed neural networks (PINNs) \cite{raissi2024physicsinformedneuralnetworksextensions} offer an alternative by incorporating physical laws directly into the learning process. PINNs train networks to satisfy governing equations by adding PDE residuals to loss functions, often achieving high accuracy with significantly less training data.

Building on this foundation, Djeumou et al. \cite{djeumouNeuralNetworksPhysicsInformed2022} developed frameworks that structure neural networks around known physical constraints, representing vector fields as compositions of known and unknown functions. Their approach yields prediction accuracy improvements of up to two orders of magnitude compared to purely data-driven baselines.

Traditional PINNs struggle with scalability and boundary condition enforcement. Gao et al. \cite{gaoPhysicsinformedGraphNeural2022} addressed these issues through discrete PINN frameworks based on Graph Convolutional Networks. By leveraging variational PDE structures and piecewise polynomial basis functions, they reduce search space dimensionality while strictly enforcing boundary conditions, particularly valuable for irregular geometries where CNN-based approaches falter.

Recent work by Tierz et al. \cite{Tierz_Alfaro_Gonz√°lez_Chinesta_Cueto_2025} advances physics-informed approaches by enforcing thermodynamic principles directly in network architecture. Their local formulation avoids complex global matrix assembly while achieving one to two orders of magnitude accuracy improvements, demonstrating strong generalization even for scenarios substantially different from training data.

Most directly relevant to our work is the neural mode approach by Wang et al. \cite{Wang_Du_Coros_Thomaszewski_2024}, which extends classical linear modal dynamics \cite{Pentland_Williams_1989} to handle large deformations. Their method trains networks to learn nonlinear corrections for each modal coordinate, minimizing system energy while maintaining the computational advantages of subspace dynamics. This approach addresses fundamental limitations of linear modes, the inability to capture large deformations and tendency toward unrealistic results, while preserving interpretability often lacking in deep learning solutions.

Our work builds directly upon this foundation, extending the neural mode framework specifically to Neo-Hookean materials commonly used in organic tissue simulation. The key advantage of this approach lies in its interpretability: since we modify linear modes in physically meaningful ways, network predictions and mode combinations can be directly visualized and understood. This transparency provides confidence in results while facilitating model refinement, a crucial consideration for applications requiring both speed and reliability.
